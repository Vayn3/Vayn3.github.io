<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="Vayne"><meta name="copyright" content="Vayne"><meta name="generator" content="Hexo 5.4.0"><meta name="theme" content="hexo-theme-yun"><title>pytorch深度学习实践 | Yun</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.25/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_dxory92pb0h.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link rel="icon" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"hostname":"example.com","root":"/","title":["V","a","y","n","e"],"version":"1.6.2","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"搜索...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）"},"anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/utils.js"></script><script src="/js/hexo-theme-yun.js"></script><meta name="description" content="来源：B站刘二大人 主要记录各章代码及思路 [TOC] 线性模型本章拟合一个线性模型：wx 对w的选取 采用最粗暴的方法，打印出所有w及其loss，来看哪个效果最好 代码注意 for in zip 的用法 1234567891011121314151617181920212223242526272829import numpy as npimport matplotlib.pyplot as pl">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch深度学习实践">
<meta property="og:url" content="http://example.com/2022/07/19/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/index.html">
<meta property="og:site_name" content="Yun">
<meta property="og:description" content="来源：B站刘二大人 主要记录各章代码及思路 [TOC] 线性模型本章拟合一个线性模型：wx 对w的选取 采用最粗暴的方法，打印出所有w及其loss，来看哪个效果最好 代码注意 for in zip 的用法 1234567891011121314151617181920212223242526272829import numpy as npimport matplotlib.pyplot as pl">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207191747483.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207191749971.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207220155596.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207221728046.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207202039021.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207240113316.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202211100039885.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202211100055528.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207260109535.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207260110836.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207260113451.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207300210229.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272033627.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272038911.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272048310.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272050936.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272056433.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272056706.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272057774.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272057360.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207301723795.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207301738955.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207301742889.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207301743570.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207311355909.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207311400355.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207311405840.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207311405829.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207311410536.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208041924766.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060023719.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060036629.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060042985.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060048943.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060050137.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060056155.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060059372.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060105111.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060105472.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060106248.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060109145.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060109040.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060111257.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060111850.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060116466.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060119820.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060122211.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060123802.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060123756.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060125627.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208080136075.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208080139490.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208080150197.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208080152810.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208081818436.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208081818928.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208081818575.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208082055275.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208082100696.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208082101338.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208082102013.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101358795.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101403058.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101407738.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101409302.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101411653.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101412930.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101414487.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101418683.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101418098.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101420732.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101421097.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101424036.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101430157.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101430277.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101433834.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101435321.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101436926.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101436176.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101445712.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101443946.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101442489.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101451863.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101453236.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101455502.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101504816.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101504345.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101505879.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101505927.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130017335.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130023250.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130024600.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130117994.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130117558.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130124007.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130124574.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130156971.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130159919.png">
<meta property="article:published_time" content="2022-07-19T09:09:22.000Z">
<meta property="article:modified_time" content="2022-11-09T16:58:00.283Z">
<meta property="article:author" content="Vayne">
<meta property="article:tag" content="代码">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202207191747483.png"><script src="/js/ui/mode.js"></script></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="Vayne"><img width="96" loading="lazy" src="/images/touxiang.jpg" alt="Vayne"></a><div class="site-author-name"><a href="/about/">Vayne</a></div><span class="site-name">Yun</span><sub class="site-subtitle"></sub><div class="site-desciption">Blog</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">30</span></a></div><div class="site-state-item"><a href="/categories/" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">6</span></a></div><div class="site-state-item"><a href="/tags/" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">14</span></a></div><a class="site-state-item hty-icon-button" target="_blank" rel="noopener" href="https://yun.yunyoujun.cn" title="文档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-settings-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://qm.qq.com/cgi-bin/qm/qr?k=kZJzggTTCf4SpvEQ8lXWoi5ZjhAx0ILZ&amp;jump_from=webapi" title="QQ 群 1050458482" target="_blank" style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/YunYouJun" title="GitHub" target="_blank" style="color:#6e5494"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://weibo.com/jizhideyunyoujun" title="微博" target="_blank" style="color:#E6162D"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-weibo-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.douban.com/people/yunyoujun/" title="豆瓣" target="_blank" style="color:#007722"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-douban-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://music.163.com/#/user/home?id=247102977" title="网易云音乐" target="_blank" style="color:#C20C0C"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-netease-cloud-music-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.zhihu.com/people/yunyoujun/" title="知乎" target="_blank" style="color:#0084FF"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhihu-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/1579790" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/about/white-qrcode-and-search.jpg" title="微信公众号" target="_blank" style="color:#1AAD19"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-2-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://twitter.com/YunYouJun" title="Twitter" target="_blank" style="color:#1da1f2"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-twitter-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://t.me/elpsycn" title="Telegram Channel" target="_blank" style="color:#0088CC"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-telegram-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:me@yunyoujun.cn" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://travellings.link" title="Travelling" target="_blank" style="color:var(--hty-text-color)"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-train-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="我的小伙伴们" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">线性模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="toc-number">2.</span> <span class="toc-text">梯度下降</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">3.</span> <span class="toc-text">反向传播</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#pytorch%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">4.</span> <span class="toc-text">pytorch实现线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4"><span class="toc-number">4.1.</span> <span class="toc-text">步骤</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-number">4.2.</span> <span class="toc-text">代码</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-number">5.</span> <span class="toc-text">逻辑回归</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E5%A4%9A%E7%BB%B4%E7%89%B9%E5%BE%81%E8%BE%93%E5%85%A5"><span class="toc-number">6.</span> <span class="toc-text">处理多维特征输入</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.1.</span> <span class="toc-text">构建模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">7.</span> <span class="toc-text">加载数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">7.1.</span> <span class="toc-text">代码实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="toc-number">8.</span> <span class="toc-text">多分类问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Softmax%E5%87%BD%E6%95%B0%EF%BC%9A"><span class="toc-number">8.1.</span> <span class="toc-text">Softmax函数：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">8.2.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB"><span class="toc-number">8.3.</span> <span class="toc-text">图像识别</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80"><span class="toc-number">9.</span> <span class="toc-text">卷积神经网络基础</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%8E%9F%E7%90%86"><span class="toc-number">9.1.</span> <span class="toc-text">卷积原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E8%BF%87%E7%A8%8B"><span class="toc-number">9.1.1.</span> <span class="toc-text">卷积过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E6%9E%84%E6%88%90"><span class="toc-number">9.1.2.</span> <span class="toc-text">卷积核的构成</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%8F%82%E6%95%B0"><span class="toc-number">9.2.</span> <span class="toc-text">常用参数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#padding"><span class="toc-number">9.2.1.</span> <span class="toc-text">padding</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#stride"><span class="toc-number">9.2.2.</span> <span class="toc-text">stride</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#maxpooling"><span class="toc-number">9.2.3.</span> <span class="toc-text">maxpooling</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8"><span class="toc-number">9.3.</span> <span class="toc-text">应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%81%E7%A8%8B"><span class="toc-number">9.3.1.</span> <span class="toc-text">流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81-1"><span class="toc-number">9.3.2.</span> <span class="toc-text">代码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E9%AB%98%E7%BA%A7%E7%AF%87"><span class="toc-number">10.</span> <span class="toc-text">卷积高级篇</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Googlenet"><span class="toc-number">10.1.</span> <span class="toc-text">Googlenet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#inception-module"><span class="toc-number">10.1.1.</span> <span class="toc-text">inception module</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-1"><span class="toc-number">10.1.1.1.</span> <span class="toc-text">代码实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%EF%BC%9AResidual-net"><span class="toc-number">10.2.</span> <span class="toc-text">解决梯度消失：Residual net</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-2"><span class="toc-number">10.2.1.</span> <span class="toc-text">代码实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80"><span class="toc-number">11.</span> <span class="toc-text">循环神经网络基础</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA"><span class="toc-number">11.1.</span> <span class="toc-text">构建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80"><span class="toc-number">11.1.1.</span> <span class="toc-text">一</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C"><span class="toc-number">11.1.2.</span> <span class="toc-text">二</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8"><span class="toc-number">11.2.</span> <span class="toc-text">简单应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%EF%BC%9Ahello-gt-ohlol"><span class="toc-number">11.2.1.</span> <span class="toc-text">一：hello -&gt;ohlol</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#embedding"><span class="toc-number">11.3.</span> <span class="toc-text">embedding</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%AB%98%E7%BA%A7"><span class="toc-number">12.</span> <span class="toc-text">循环神经网络高级</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE"><span class="toc-number">12.1.</span> <span class="toc-text">处理数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B"><span class="toc-number">12.2.</span> <span class="toc-text">模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Bi-direction"><span class="toc-number">12.2.1.</span> <span class="toc-text">Bi-direction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E9%80%9F"><span class="toc-number">12.2.2.</span> <span class="toc-text">加速</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81-2"><span class="toc-number">12.3.</span> <span class="toc-text">代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8-1"><span class="toc-number">12.4.</span> <span class="toc-text">应用</span></a></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://example.com/2022/07/19/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="Vayne"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="Yun"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">pytorch深度学习实践</h1><div class="post-meta"><div class="post-time" style="display:inline-block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2022-07-19 17:09:22" itemprop="dateCreated datePublished" datetime="2022-07-19T17:09:22+08:00">2022-07-19</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-2-line"></use></svg></span> <time title="修改时间：2022-11-10 00:58:00" itemprop="dateModified" datetime="2022-11-10T00:58:00+08:00">2022-11-10</time></div><div class="post-classify"><span class="post-category"> <span class="post-meta-item-icon" style="margin-right:3px;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/%E7%AC%94%E8%AE%B0/" style="--text-color:dimgray" itemprop="url" rel="index"><span itemprop="text">笔记</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag-item" href="/tags/%E4%BB%A3%E7%A0%81/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">代码</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#0078E7;"><p>来源：B站刘二大人</p>
<p>主要记录各章代码及思路</p>
<p>[TOC]</p>
<h1 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h1><p>本章拟合一个线性模型：wx 对w的选取</p>
<p>采用最粗暴的方法，打印出所有w及其loss，来看哪个效果最好</p>
<p><strong>代码注意</strong></p>
<p>for in zip 的用法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x_data = [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]</span><br><span class="line">y_data = [<span class="number">2.0</span>, <span class="number">4.0</span>, <span class="number">6.0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x * w</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算损失</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="keyword">return</span> (y_pred - y) * (y_pred - y)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#遍历w</span></span><br><span class="line">w_list = []</span><br><span class="line">mse_lst = []</span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> np.arange(<span class="number">0.0</span>, <span class="number">4.1</span>, <span class="number">0.1</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;w=&#x27;</span>, w)</span><br><span class="line">    l_sum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x_val, y_val <span class="keyword">in</span> <span class="built_in">zip</span>(x_data, y_data):</span><br><span class="line">        y_pred_val = forward(x_val)</span><br><span class="line">        loss_val = loss(x_val, y_val)</span><br><span class="line">        l_sum += loss_val</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\t&#x27;</span>, x_val, y_val, y_pred_val, loss_val)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;mse=&#x27;</span>, l_sum / <span class="number">3</span>)</span><br><span class="line">    w_list.append(w)</span><br><span class="line">    mse_lst.append(l_sum / <span class="number">3</span>)</span><br></pre></td></tr></table></figure>





<h1 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h1><p>原理：</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207191747483.png" alt="image-20220719174708420" loading="lazy"></p>
<p><strong>推导求梯度</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207191749971.png" alt="image-20220719174927901" loading="lazy"></p>
<p><strong>代码注意</strong></p>
<p>1.根据公式，求cost时需要求和，求梯度同理</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207220155596.png" alt="image-20220722015545496" loading="lazy"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">x_data = [1.0, 2.0, 3.0]</span><br><span class="line">y_data = [2.0, 4.0, 6.0]</span><br><span class="line">w = 1.0</span><br><span class="line"></span><br><span class="line">def forward(x):</span><br><span class="line">    return x * w</span><br><span class="line"></span><br><span class="line">def cost(xs, ys):</span><br><span class="line">    cost = 0</span><br><span class="line">    for x, y in zip(xs, ys):</span><br><span class="line">        y_pred = forward(x)</span><br><span class="line">        cost += (y_pred - y) ** 2</span><br><span class="line">    return cost / len(xs)</span><br><span class="line"></span><br><span class="line">def gradient(xs, ys):</span><br><span class="line">    grad = 0</span><br><span class="line">    for x, y in zip(xs, ys):</span><br><span class="line">        grad += 2 * x * (x * w - y)</span><br><span class="line">    return grad / len(xs)</span><br><span class="line"></span><br><span class="line">print(&#x27;predict (before training)&#x27;, 4, forward(4))</span><br><span class="line">for epoch in range(100):</span><br><span class="line">    cost_val = cost(x_data, y_data)</span><br><span class="line">    grad_val = gradient(x_data, y_data)</span><br><span class="line">    w -= 0.1 * grad_val</span><br><span class="line">    print(&#x27;Epoch:&#x27;, epoch, &#x27;w=&#x27;, w, &#x27;loss=&#x27;, cost_val)</span><br><span class="line">print(&#x27;predict (after training)&#x27;, 4, forward(4))</span><br></pre></td></tr></table></figure>



<p><strong>随机梯度下降</strong>：对每一个样本来更新而不是求和求平均</p>
<p>两者区别</p>
<p>求gradie和loss时只求一个，而</p>
<p>代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">x_data = [1.0, 2.0, 3.0]</span><br><span class="line">y_data = [2.0, 4.0, 6.0]</span><br><span class="line">w = 1.0</span><br><span class="line"></span><br><span class="line">def forward(x):</span><br><span class="line">    return x * w</span><br><span class="line"></span><br><span class="line">def loss(x, y):</span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    return (y_pred - y) ** 2</span><br><span class="line"></span><br><span class="line">def gradient(x, y):</span><br><span class="line">    return 2 * x * (x * w - y)</span><br><span class="line"></span><br><span class="line">print(&#x27;predict (before training)&#x27;, 4, forward(4))</span><br><span class="line"></span><br><span class="line">for epoch in range(100):</span><br><span class="line">    for x, y in zip(x_data, y_data):</span><br><span class="line">        grad_val = gradient(x, y)</span><br><span class="line">        w -= 0.01 * grad_val</span><br><span class="line">        print(&quot;\tgrad: &quot;, x, y, grad_val)</span><br><span class="line">        l = loss(x, y)</span><br><span class="line"></span><br><span class="line">    print(&#x27;Epoch:&#x27;, epoch, &#x27;w=&#x27;, w, &#x27;loss=&#x27;, l)</span><br><span class="line">print(&#x27;predict (after training)&#x27;, 4, forward(4))</span><br></pre></td></tr></table></figure>

<p>两者的性能与时间</p>
<p>实际应用中一般取折中：batch</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207221728046.png" alt="image-20220722172811959" loading="lazy"></p>
<p>​    </p>
<h1 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h1><p><strong>例</strong></p>
<p>构建一个计算图</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207202039021.png" alt="image-20220720203944927" loading="lazy"></p>
<p>代码：</p>
<p>本算法中反向传播主要体现在，l.backward()。调用该方法后w.grad由None更新为Tensor类型，且w.grad.data的值用于后续w.data的更新。</p>
<pre><code>l.backward()会把计算图中所有需要梯度(grad)的地方都会求出来，然后把梯度都存在对应的待求的参数中，最终计算图被释放。
取tensor中的data是不会构建计算图的。  
</code></pre>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">x_data = [1.0, 2.0, 3.0]</span><br><span class="line">y_data = [2.0, 4.0, 6.0]</span><br><span class="line"></span><br><span class="line">w = torch.Tensor([1.0])</span><br><span class="line">w.requires_grad = True</span><br><span class="line"></span><br><span class="line">def forward(x):</span><br><span class="line">    return w * x</span><br><span class="line"></span><br><span class="line">def loss(x, y):</span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    return (y_pred - y) ** 2</span><br><span class="line"></span><br><span class="line">print(&#x27;predict (before training)&#x27;, 4, forward(4).item())</span><br><span class="line"></span><br><span class="line">for epoch in range(100):</span><br><span class="line">    for x, y in zip(x_data, y_data):</span><br><span class="line">        l = loss(x, y)</span><br><span class="line">        l.backward()</span><br><span class="line">        print(&#x27;\tgrad:&#x27;, x, y, w.grad.item())</span><br><span class="line">        w.data = w.data - 0.01 * w.grad.data</span><br><span class="line"></span><br><span class="line">        w.grad.data.zero_()</span><br><span class="line"></span><br><span class="line">    print(&quot;progress：&quot;, epoch, l.item())</span><br><span class="line"></span><br><span class="line">print(&#x27;predict (after training)&#x27;, 4, forward(4).item())</span><br></pre></td></tr></table></figure>

<h1 id="pytorch实现线性回归"><a href="#pytorch实现线性回归" class="headerlink" title="pytorch实现线性回归"></a>pytorch实现线性回归</h1><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207240113316.png" alt="image-20220724011307241" loading="lazy"></p>
<p>module部分的目的：构造计算图</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p><strong>1.模型的构建</strong></p>
<p>module类中需要实现两个方法：init和forward</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202211100039885.png" alt="image-20221110003855694" loading="lazy"></p>
<p><strong>2.loss and 优化器</strong></p>
<p><strong>3.训练</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202211100055528.png" alt="image-20221110005546400" loading="lazy"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x_data = torch.Tensor([[<span class="number">1.0</span>], [<span class="number">2.0</span>], [<span class="number">3.0</span>]])</span><br><span class="line">y_data = torch.Tensor([[<span class="number">2.0</span>], [<span class="number">4.0</span>], [<span class="number">6.0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearModel</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LinearModel, self).__init__()</span><br><span class="line">        self.linear = torch.nn.Linear(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        y_pred = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line">model = LinearModel()</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.MSELoss(size_average = <span class="literal">False</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr = <span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred, y_data)</span><br><span class="line">    <span class="built_in">print</span>(epoch, loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w = &#x27;</span>, model.linear.weight.item())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b = &#x27;</span>, model.linear.bias.item())</span><br><span class="line"></span><br><span class="line">x_test = torch.Tensor([[<span class="number">4.0</span>]])</span><br><span class="line">y_test = model(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;y_pred = &#x27;</span>, y_test.data)</span><br></pre></td></tr></table></figure>



<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>和线型回归的差别：</p>
<p><strong>1.用了sigmoid函数</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207260109535.png" alt="image-20220726010922416" loading="lazy"></p>
<p><strong>2.用BCELOSS</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207260110836.png" alt="image-20220726011045758" loading="lazy"></p>
<p><strong>总结</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207260113451.png" alt="image-20220726011347338" loading="lazy"></p>
<p><strong>代码</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">x_data = torch.Tensor([[1.0], [2.0], [3.0]])</span><br><span class="line">y_data = torch.Tensor([[2.0], [4.0], [6.0]])</span><br><span class="line"></span><br><span class="line">class LinearModel(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(LinearModel, self).__init__()</span><br><span class="line">        self.linear = torch.nn.Linear(1, 1)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        y_pred = self.linear(x)</span><br><span class="line">        return y_pred</span><br><span class="line">model = LinearModel()</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.MSELoss(size_average = False)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)</span><br><span class="line"></span><br><span class="line">for epoch in range(1000):</span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred, y_data)</span><br><span class="line">    print(epoch, loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">print(&#x27;w = &#x27;, model.linear.weight.item())</span><br><span class="line">print(&#x27;b = &#x27;, model.linear.bias.item())</span><br><span class="line"></span><br><span class="line">x_test = torch.Tensor([[4.0]])</span><br><span class="line">y_test = model(x_test)</span><br><span class="line">print(&#x27;y_pred = &#x27;, y_test.data)</span><br></pre></td></tr></table></figure>

<p>总结：</p>
<p>1、Module实现了魔法函数__call__()，call()里面有一条语句是要调用forward()。因此新写的类中需要重写forward()覆盖掉父类中的forward()</p>
<p>2、call函数的另一个作用是可以直接在对象后面加()，例如实例化的model对象，和实例化的linear对象</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207300210229.png" alt="image-20220730021009139" loading="lazy"></p>
<h1 id="处理多维特征输入"><a href="#处理多维特征输入" class="headerlink" title="处理多维特征输入"></a>处理多维特征输入</h1><p>record：数据的一行</p>
<p>feature：一列</p>
<p>对多维数据处理的推导</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272033627.png" alt="image-20220727203332549" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272038911.png" alt="image-20220727203859846" loading="lazy"></p>
<p><strong>用一个简单地神经网络模型降维</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272048310.png" alt="image-20220727204844237" loading="lazy"></p>
<h2 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h2><p><strong>步骤</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272050936.png" alt="image-20220727205056871" loading="lazy"></p>
<p><strong>1.加载数据</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272056433.png" alt="image-20220727205604226" loading="lazy"></p>
<p><strong>2.model</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272056706.png" alt="image-20220727205637617" loading="lazy"></p>
<p><strong>3.损失</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272057774.png" alt="image-20220727205716712" loading="lazy"></p>
<p><strong>4.训练</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207272057360.png" alt="image-20220727205737296" loading="lazy"></p>
<p><strong>代码</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">xy = np.loadtxt(&#x27;diabetes.csv&#x27;, delimiter=&#x27;,&#x27;, dtype=np.float32)</span><br><span class="line">x_data = torch.from_numpy(xy[:, :-1])</span><br><span class="line">y_data = torch.from_numpy(xy[:, [-1]])</span><br><span class="line"></span><br><span class="line">class Model(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(8, 6)</span><br><span class="line">        self.linear2 = torch.nn.Linear(6, 4)</span><br><span class="line">        self.linear3 = torch.nn.Linear(4, 1)</span><br><span class="line">        self.sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.sigmoid(self.linear1(x))</span><br><span class="line">        x = self.sigmoid(self.linear2(x))</span><br><span class="line">        x = self.sigmoid(self.linear3(x))</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.BCELoss(size_average=True)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=0.01)</span><br><span class="line"></span><br><span class="line">for epoch in range(1000):</span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred, y_data)</span><br><span class="line">    print(epoch, loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>



<h1 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h1><p><strong>Dataloader的功能</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207301723795.png" alt="image-20220730172309692" loading="lazy"></p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>注意：</p>
<p>1.Dataset是一个抽象类，不能实例化，只能被子类继承</p>
<p>2.在Dataset子类里我们需要实现以下方法：</p>
<p>1）init</p>
<p>2）getitem 一个魔法方法，支持下标操作数据集</p>
<p>3）len 魔法方法，可以反馈数据条数</p>
<p><strong>具体实现</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207301738955.png" alt="image-20220730173801863" loading="lazy"></p>
<p>training</p>
<p>：dataset自动将x y转换成了tensor</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207301742889.png" alt="image-20220730174202822" loading="lazy"></p>
<p>总结：</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207301743570.png" alt="image-20220730174301409" loading="lazy"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import numpy as np</span><br><span class="line">from torch.utils.data import Dataset</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line"></span><br><span class="line"># prepare dataset</span><br><span class="line"></span><br><span class="line">class DiabetesDataset(Dataset):</span><br><span class="line">    def __init__(self, filepath):</span><br><span class="line">        xy = np.loadtxt(filepath, delimiter=&#x27;,&#x27;, dtype=np.float32)</span><br><span class="line">        self.len = xy.shape[0]</span><br><span class="line">        self.x_data = torch.from_numpy(xy[:, :-1])</span><br><span class="line">        self.y_data = torch.from_numpy(xy[:, [-1]])</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, index):</span><br><span class="line">        return self.x_data[index], self.y_data[index]</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return self.len</span><br><span class="line"></span><br><span class="line">dataset = DiabetesDataset(&#x27;diabetes.csv&#x27;)</span><br><span class="line">train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># design model using class</span><br><span class="line"></span><br><span class="line">class Model(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(8, 6)</span><br><span class="line">        self.linear2 = torch.nn.Linear(6, 4)</span><br><span class="line">        self.linear3 = torch.nn.Linear(4, 1)</span><br><span class="line">        self.sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.sigmoid(self.linear1(x))</span><br><span class="line">        x = self.sigmoid(self.linear2(x))</span><br><span class="line">        x = self.sigmoid(self.linear3(x))</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># construct loss and optimizer</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.BCELoss(size_average=True)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=0.01)</span><br><span class="line"></span><br><span class="line"># training cycle forward, backward, update</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    for epoch in range(100):</span><br><span class="line">        for i, data in enumerate(train_loader, 0):</span><br><span class="line">            # prepare data</span><br><span class="line">            inputs, labels = data</span><br><span class="line">            # forward</span><br><span class="line">            y_pred = model(inputs)</span><br><span class="line">            loss = criterion(y_pred, labels)</span><br><span class="line">            print(epoch, i, loss.item())</span><br><span class="line">            # backward</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            # update</span><br><span class="line">            optimizer.step()</span><br></pre></td></tr></table></figure>



<h1 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h1><h2 id="Softmax函数："><a href="#Softmax函数：" class="headerlink" title="Softmax函数："></a>Softmax函数：</h2><p>先进行ex方，再归一化</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207311355909.png" alt="image-20220731135542846" loading="lazy"></p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>y的标签编码方式是one-hot。我对one-hot的理解是只有一位是1，其他位为0</p>
<p>多分类问题，标签y的类型是LongTensor。比如说0-9分类问题，如果y = torch.LongTensor([3])，对应的one-hot是[0,0,0,1,0,0,0,0,0,0].(这里要注意，如果使用了one-hot，标签y的类型是LongTensor，糖尿病数据集中的target的类型是FloatTensor)</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207311400355.png" alt="image-20220731140014240" loading="lazy"></p>
<p><strong>不用pytorch实现</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207311405840.png" alt="image-20220731140508774" loading="lazy"></p>
<p><strong>用pytorch实现</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207311405829.png" alt="image-20220731140539754" loading="lazy"></p>
<p>从softmax开始全部用交叉熵包括了 也就是说神经网络出来的结果不用激活</p>
<p>即：</p>
<p>交叉熵损失 = softmax + nll损失</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202207311410536.png" alt="image-20220731141031494" loading="lazy"></p>
<h2 id="图像识别"><a href="#图像识别" class="headerlink" title="图像识别"></a>图像识别</h2><p>使用transform转换得到一个图片张量，使通道在前</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208041924766.png" alt="image-20220804192441675" loading="lazy"></p>
<h1 id="卷积神经网络基础"><a href="#卷积神经网络基础" class="headerlink" title="卷积神经网络基础"></a>卷积神经网络基础</h1><p>整体过程</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060023719.png" alt="image-20220806002336625" loading="lazy"></p>
<h2 id="卷积原理"><a href="#卷积原理" class="headerlink" title="卷积原理"></a>卷积原理</h2><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060036629.png" alt="image-20220806003639535" loading="lazy"></p>
<h3 id="卷积过程"><a href="#卷积过程" class="headerlink" title="卷积过程"></a>卷积过程</h3><p>单通道</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060042985.png" alt="image-20220806004220913" loading="lazy"></p>
<p>三通道：叠起来进行张量运算</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060048943.png" alt="image-20220806004806841" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060050137.png" alt="image-20220806005001043" loading="lazy"></p>
<p>上面的输出通道均为1，那么如何输出通道为m呢？</p>
<p><strong>增加卷积核</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060056155.png" alt="image-20220806005616081" loading="lazy"></p>
<p>其中，<strong>卷积核的通道与输入一致，卷积核的个数与输出的通道一致</strong></p>
<p>从而可以得出卷积核的构成</p>
<h3 id="卷积核的构成"><a href="#卷积核的构成" class="headerlink" title="卷积核的构成"></a>卷积核的构成</h3><p>4个维度</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060059372.png" alt="image-20220806005902291" loading="lazy"></p>
<h2 id="常用参数"><a href="#常用参数" class="headerlink" title="常用参数"></a>常用参数</h2><h3 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h3><p>填充维度</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060105111.png" alt="image-20220806010506038" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060105472.png" alt="image-20220806010542391" loading="lazy"></p>
<p>实现代码</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060106248.png" alt="image-20220806010624175" loading="lazy"></p>
<h3 id="stride"><a href="#stride" class="headerlink" title="stride"></a>stride</h3><p>卷积核移动的步数</p>
<p>可降低输出维度</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060109145.png" alt="image-20220806010951080" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060109040.png" alt="image-20220806010956975" loading="lazy"></p>
<h3 id="maxpooling"><a href="#maxpooling" class="headerlink" title="maxpooling"></a>maxpooling</h3><p>分割成几部分然后取各部分最大值</p>
<p>默认stride=2</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060111257.png" alt="image-20220806011133192" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060111850.png" alt="image-20220806011152785" loading="lazy"></p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>对minist数据集训练</p>
<h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060116466.png" alt="image-20220806011639379" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060119820.png" alt="image-20220806011906724" loading="lazy"></p>
<h3 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h3><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060122211.png" alt="image-20220806012235126" loading="lazy"></p>
<p>train和test过程和之前一样，只是加一个转到gpu训练</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060123802.png" alt="image-20220806012317721" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060123756.png" alt="image-20220806012324682" loading="lazy"></p>
<p>结果</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208060125627.png" alt="image-20220806012518533" loading="lazy"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torchvision import transforms</span><br><span class="line">from torchvision import datasets</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import torch.optim as optim</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"># prepare dataset</span><br><span class="line">batch_size = 64</span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((0.1307, ), (0.3081, ))</span><br><span class="line">])</span><br><span class="line">train_dataset = datasets.MNIST(root=&#x27;../dataset/mnist/&#x27;, train=True, download=True, transform=transform)</span><br><span class="line">train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)</span><br><span class="line">test_dataset = datasets.MNIST(root=&#x27;../dataset/mnist/&#x27;, train=False, download=True, transform=transform)</span><br><span class="line">test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"># design model using class</span><br><span class="line">class Net(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5)</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5)</span><br><span class="line">        self.pooling = torch.nn.MaxPool2d(2)</span><br><span class="line">        self.fc = torch.nn.Linear(320, 10)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        batch_size = x.size(0)</span><br><span class="line">        x = F.relu(self.pooling(self.conv1(x)))</span><br><span class="line">        x = F.relu(self.pooling(self.conv2(x)))</span><br><span class="line">        x = x.view(batch_size, -1)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># construct loss and optimizer</span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># training cycle forward, backward, update</span><br><span class="line">def train(epoch):</span><br><span class="line">    running_loss = 0.0</span><br><span class="line">    for batch_idx, data in enumerate(train_loader, 0):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        inputs, target = inputs.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        if batch_idx % 300 == 299:</span><br><span class="line">            print(&#x27;[%d, %5d] loss: %.3f&#x27; % (epoch + 1, batch_idx + 1, running_loss / 300))</span><br><span class="line">            running_loss = 0.0</span><br><span class="line"></span><br><span class="line">def test():</span><br><span class="line">    correct = 0</span><br><span class="line">    total = 0</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for data in test_loader:</span><br><span class="line">            images, labels = data</span><br><span class="line">            images, labels = images.to(device), labels.to(device)</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            _, predicted = torch.max(outputs.data, dim=1)</span><br><span class="line">            total += labels.size(0)</span><br><span class="line">            correct += (predicted == labels).sum().item()</span><br><span class="line">    print(&#x27;accuracy on test set: %d %% [%d/%d]&#x27; % (100 * correct / total, correct, total))</span><br><span class="line">    return correct / total</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    epoch_list = []</span><br><span class="line">    acc_list = []</span><br><span class="line"></span><br><span class="line">    for epoch in range(10):</span><br><span class="line">        train(epoch)</span><br><span class="line">        acc = test()</span><br><span class="line">        epoch_list.append(epoch)</span><br><span class="line">        acc_list.append(acc)</span><br><span class="line"></span><br><span class="line">    plt.plot(epoch_list,acc_list)</span><br><span class="line">    plt.ylabel(&#x27;acc&#x27;)</span><br><span class="line">    plt.xlabel(&#x27;epoch&#x27;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>



<h1 id="卷积高级篇"><a href="#卷积高级篇" class="headerlink" title="卷积高级篇"></a>卷积高级篇</h1><h2 id="Googlenet"><a href="#Googlenet" class="headerlink" title="Googlenet"></a>Googlenet</h2><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208080136075.png" alt="image-20220808013628859" loading="lazy"></p>
<p>为了减少代码冗余，将类似的模块封装成类，得到：inception module</p>
<h3 id="inception-module"><a href="#inception-module" class="headerlink" title="inception module"></a>inception module</h3><p>作用：将各种常用的超参数都添加进去从而自动选出比较有效的</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208080139490.png" alt="image-20220808013949408" loading="lazy"></p>
<p><strong>解释</strong></p>
<p>concatenate：将张量拼接到一块</p>
<p>1*1conv: 1 * 1的卷积,作用是改变通道，可以降低计算量</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208080150197.png" alt="image-20220808015003103" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208080152810.png" alt="image-20220808015222728" loading="lazy"></p>
<h4 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h4><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208081818436.png" alt="image-20220808181802307" loading="lazy"></p>
<p>最后要将其拼接起来</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208081818928.png" alt="image-20220808181831841" loading="lazy"></p>
<p>拼接的代码：</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208081818575.png" alt="image-20220808181844511" loading="lazy"></p>
<h2 id="解决梯度消失：Residual-net"><a href="#解决梯度消失：Residual-net" class="headerlink" title="解决梯度消失：Residual net"></a>解决梯度消失：Residual net</h2><p>  <img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208082055275.png" alt="image-20220808205516115" loading="lazy"></p>
<p>r中两层的输出必须和输入x维度一样才能做运算</p>
<h3 id="代码实现-2"><a href="#代码实现-2" class="headerlink" title="代码实现"></a>代码实现</h3><p>位置在?</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208082100696.png" alt="image-20220808210035600" loading="lazy"></p>
<p><strong>代码：</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208082101338.png" alt="image-20220808210104253" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208082102013.png" alt="image-20220808210248904" loading="lazy"></p>
<h1 id="循环神经网络基础"><a href="#循环神经网络基础" class="headerlink" title="循环神经网络基础"></a>循环神经网络基础</h1><p>适用于时间序列型</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101358795.png" alt="image-20220810135834689" loading="lazy"></p>
<p>用同一个层反复训练</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101403058.png" alt="image-20220810140318961" loading="lazy"></p>
<p>将h和x放矩阵里一起运算</p>
<p>本质其实就一个线性层</p>
<h2 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h2><p>有两种方式，一是构建自己的rnncell 自己写处理序列的循环</p>
<p>二是直接用rnn</p>
<h3 id="一"><a href="#一" class="headerlink" title="一"></a>一</h3><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101407738.png" alt="image-20220810140720649" loading="lazy"></p>
<p>实例化时要满足维度要求</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101409302.png" alt="image-20220810140952219" loading="lazy"></p>
<p><strong>例</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101411653.png" alt="image-20220810141137586" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101412930.png" alt="image-20220810141238853" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101414487.png" alt="image-20220810141400398" loading="lazy"></p>
<p><strong>注意</strong></p>
<p>最重要的就是两个维度</p>
<h3 id="二"><a href="#二" class="headerlink" title="二"></a>二</h3><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101418683.png" alt="image-20220810141801585" loading="lazy"></p>
<p>​    </p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101418098.png" alt="image-20220810141838997" loading="lazy"></p>
<p>numlayers指在上面再加n个rnn cell</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101420732.png" alt="image-20220810142041627" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101421097.png" alt="image-20220810142154001" loading="lazy"></p>
<h2 id="简单应用"><a href="#简单应用" class="headerlink" title="简单应用"></a>简单应用</h2><h3 id="一：hello-gt-ohlol"><a href="#一：hello-gt-ohlol" class="headerlink" title="一：hello -&gt;ohlol"></a>一：hello -&gt;ohlol</h3><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101424036.png" alt="image-20220810142415957" loading="lazy"></p>
<p>首先将字符用字典转换成数字 才能用rnn</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101430157.png" alt="image-20220810143013081" loading="lazy"></p>
<p><strong>代码</strong></p>
<p>用一来解决</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101430277.png" alt="image-20220810143042210" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101433834.png" alt="image-20220810143347751" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101435321.png" alt="image-20220810143516217" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101436926.png" alt="image-20220810143613862" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101436176.png" alt="image-20220810143621092" loading="lazy"></p>
<p>用二来解决</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101445712.png" alt="image-20220810144516637" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101443946.png" alt="image-20220810144344838" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101442489.png" alt="image-20220810144219394" loading="lazy"></p>
<h2 id="embedding"><a href="#embedding" class="headerlink" title="embedding"></a>embedding</h2><p>one-hot有时维度过高，需用embedding降维</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101451863.png" alt="image-20220810145141775" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101453236.png" alt="image-20220810145308154" loading="lazy"></p>
<p>这样就将可能很长的0000010000…..的转换成低维度了</p>
<p>得到网络</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101455502.png" alt="image-20220810145517411" loading="lazy"></p>
<p>代码：</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101504816.png" alt="image-20220810150451741" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101504345.png" alt="image-20220810150416224" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101505879.png" alt="image-20220810150509796" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208101505927.png" alt="image-20220810150516832" loading="lazy"></p>
<h1 id="循环神经网络高级"><a href="#循环神经网络高级" class="headerlink" title="循环神经网络高级"></a>循环神经网络高级</h1><p>目标：训练一个模型，可以分辨出一个名字属于哪个国家</p>
<h2 id="处理数据"><a href="#处理数据" class="headerlink" title="处理数据"></a>处理数据</h2><p>用ascii将字符串序列转换成数值序列</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130017335.png" alt="image-20220813001759211" loading="lazy"></p>
<p><strong>注意：这里的数值表示128维on—hot的值 只是对于embedding来说只要知道为1的位置即可</strong></p>
<p>例如77表示000…1000…第77个为1</p>
<p>为了构成张量需将所有数据填充</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130023250.png" alt="image-20220813002307135" loading="lazy"></p>
<p>对于目标值国家，构造索引标签</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130024600.png" alt="image-20220813002433511" loading="lazy"></p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>采用改进的GRU</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130117994.png" alt="image-20220813011734894" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130117558.png" alt="image-20220813011752486" loading="lazy"></p>
<p>其中参数：bidirection是什么？</p>
<h3 id="Bi-direction"><a href="#Bi-direction" class="headerlink" title="Bi-direction"></a>Bi-direction</h3><p>指双向传播算法，沿着序列正向计算的同时还会反向计算，并将两者结果hn拼接</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130124007.png" alt="image-20220813012405905" loading="lazy"></p>
<p>隐含层同时也有两个</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130124574.png" alt="image-20220813012445509" loading="lazy"></p>
<h3 id="加速"><a href="#加速" class="headerlink" title="加速"></a>加速</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gru_input = pack_padded_sequence(embedding, seq_lengths) #加速</span><br></pre></td></tr></table></figure>

<p>原理</p>
<p>首先排序 然后embedding</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130156971.png" alt="image-20220813015656855" loading="lazy"></p>
<p>然后舍弃掉0从长到短拼接起来</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202208130159919.png" alt="image-20220813015911795" loading="lazy"></p>
<h2 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line">import csv</span><br><span class="line">import gzip</span><br><span class="line">import time</span><br><span class="line">import torch</span><br><span class="line">from torch.utils.data import Dataset</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from torch.nn.utils.rnn import pack_padded_sequence</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">HIDDEN_SIZE = 100</span><br><span class="line">BATCH_SIZE = 256</span><br><span class="line">N_LAYER = 2</span><br><span class="line">N_EPOCHS = 100</span><br><span class="line">N_CHARS = 128</span><br><span class="line">USE_GPU = True</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class NameDataset(Dataset):</span><br><span class="line">    def __init__(self, is_train_set = True):</span><br><span class="line">        filename = &#x27;names_train.csv.gz&#x27; if is_train_set else &#x27;names_test.csv.gz&#x27;</span><br><span class="line">        with gzip.open(filename, &#x27;rt&#x27;) as f:</span><br><span class="line">            reader = csv.reader(f)</span><br><span class="line">            rows = list(reader)</span><br><span class="line">        self.names = [row[0] for row in rows]</span><br><span class="line">        self.len = len(self.names)</span><br><span class="line">        self.countries = [row[1] for row in rows]</span><br><span class="line">        self.country_list = list(sorted(set(self.countries)))</span><br><span class="line">        self.country_dict = self.getCountryDict()</span><br><span class="line">        self.country_num = len(self.country_list)</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, index):</span><br><span class="line">        return self.names[index], self.country_dict[self.countries[index]]</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return self.len</span><br><span class="line"></span><br><span class="line">    def getCountryDict(self):</span><br><span class="line">        country_dict = dict()</span><br><span class="line">        for idx, country_name in enumerate(self.country_list, 0):</span><br><span class="line">            country_dict[country_name] = idx</span><br><span class="line">        return country_dict</span><br><span class="line">    def idx2country(self, index):</span><br><span class="line">        return self.country_list[index]</span><br><span class="line"></span><br><span class="line">    def getCountriesNum(self):</span><br><span class="line">        return self.country_num</span><br><span class="line"></span><br><span class="line">trainset = NameDataset(is_train_set=True)</span><br><span class="line">trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)</span><br><span class="line">testset = NameDataset(is_train_set=False)</span><br><span class="line">testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)</span><br><span class="line"></span><br><span class="line">N_COUNTRY = trainset.getCountriesNum()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class RNNClassifier(torch.nn.Module):</span><br><span class="line">    def __init__(self, input_size, hidden_size, output_size, n_layers=1, bidirectional = True):</span><br><span class="line">        super(RNNClassifier, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.n_layers = n_layers</span><br><span class="line">        self.n_directions = 2 if bidirectional else 1</span><br><span class="line"></span><br><span class="line">        self.embedding = torch.nn.Embedding(input_size, hidden_size)</span><br><span class="line">        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=bidirectional)</span><br><span class="line">        self.fc = torch.nn.Linear(hidden_size*self.n_directions, output_size)</span><br><span class="line"></span><br><span class="line">    def _int_hidden(self, batch_size):</span><br><span class="line">        hidden = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)</span><br><span class="line">        return create_tensor(hidden)</span><br><span class="line"></span><br><span class="line">    def forward(self, input, seq_lengths):</span><br><span class="line">        input = input.t()</span><br><span class="line">        batch_size = input.size(1)</span><br><span class="line"></span><br><span class="line">        hidden = self._int_hidden(batch_size)</span><br><span class="line">        embedding = self.embedding(input)</span><br><span class="line"></span><br><span class="line">        gru_input = pack_padded_sequence(embedding, seq_lengths.cpu())  # 加速</span><br><span class="line">        output, hidden = self.gru(gru_input, hidden)</span><br><span class="line">        if self.n_directions == 2:</span><br><span class="line">            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim = 1 )</span><br><span class="line">        else:</span><br><span class="line">            hidden_cat = hidden[-1]</span><br><span class="line">        fc_output = self.fc(hidden_cat)</span><br><span class="line">        return fc_output</span><br><span class="line"></span><br><span class="line">def name2list(name):</span><br><span class="line">    arr = [ord(c) for c in name]</span><br><span class="line">    return arr, len(arr)</span><br><span class="line"></span><br><span class="line">def create_tensor(tensor):</span><br><span class="line">    if USE_GPU:</span><br><span class="line">        device = torch.device(&#x27;cuda:0&#x27;)</span><br><span class="line">        tensor = tensor.to(device)</span><br><span class="line">        return tensor</span><br><span class="line"></span><br><span class="line">def make_tensors(names, countries):</span><br><span class="line">    sequences_and_lengths = [name2list(name) for name in names]</span><br><span class="line">    name_sequences = [s1[0] for s1 in sequences_and_lengths]</span><br><span class="line">    seq_lengths = torch.LongTensor([s1[1] for s1 in sequences_and_lengths])</span><br><span class="line">    countries = countries.long()</span><br><span class="line"></span><br><span class="line">    seq_tensor = torch.zeros(len(name_sequences), seq_lengths.max()).long()</span><br><span class="line">    for idx, (seq, seq_len) in enumerate(zip(name_sequences, seq_lengths), 0):</span><br><span class="line">        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)</span><br><span class="line"></span><br><span class="line">    seq_lengths, perm_idx = seq_lengths.sort(dim=0, descending=True)</span><br><span class="line">    seq_tensor = seq_tensor[perm_idx]</span><br><span class="line">    countries = countries[perm_idx]</span><br><span class="line"></span><br><span class="line">    return create_tensor(seq_tensor),\</span><br><span class="line">           create_tensor(seq_lengths),\</span><br><span class="line">           create_tensor(countries)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def trainModel():</span><br><span class="line">    total_loss = 0</span><br><span class="line">    for i, (names, countries) in enumerate(trainloader, 1):</span><br><span class="line">        inputs, seq_lengths, target = make_tensors(names, countries)</span><br><span class="line">        output = classifier(inputs, seq_lengths)</span><br><span class="line">        loss = criterion(output, target)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        total_loss += loss.item()</span><br><span class="line">        if i % 10 == 0:</span><br><span class="line">            print(f&#x27;[&#123;i * len(inputs)&#125; / &#123;len(trainset)&#125;&#x27;, end=&#x27;&#x27;)</span><br><span class="line">            print(f&#x27;loss=&#123;total_loss / (i * len(inputs))&#125;&#x27;)</span><br><span class="line">        return total_loss</span><br><span class="line"></span><br><span class="line">def testModel():</span><br><span class="line">    correct = 0</span><br><span class="line">    total = len((testset))</span><br><span class="line">    print(&quot;evaluating trainen model ...&quot;)</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for i, (names, countries) in enumerate(testloader, 1):</span><br><span class="line">            inputs, seq_lengths, target = make_tensors(names, countries)</span><br><span class="line">            output = classifier(inputs, seq_lengths)</span><br><span class="line">            pred = output.max(dim=1, keepdim=True)[1]</span><br><span class="line">            correct += pred.eq(target.view_as(pred)).sum().item()</span><br><span class="line"></span><br><span class="line">        percent = &#x27;%.2f&#x27; % (100 * correct / total)</span><br><span class="line">        print(f&#x27;Test set: Accuracy &#123;correct&#125;/&#123;total&#125; &#123;percent&#125;%&#x27;)</span><br><span class="line"></span><br><span class="line">    return correct / total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    classifier = RNNClassifier(N_CHARS,HIDDEN_SIZE,N_COUNTRY, N_LAYER)</span><br><span class="line">    if USE_GPU:</span><br><span class="line">        device = torch.device(&#x27;cuda:0&#x27;)</span><br><span class="line">        classifier.to(device)</span><br><span class="line"></span><br><span class="line">    criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = torch.optim.Adam(classifier.parameters(), lr = 0.01)</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    print(&quot;training for %d epochs...&quot; % N_EPOCHS)</span><br><span class="line">    acc_list = []</span><br><span class="line">    for epoch in range(1, N_EPOCHS + 1):</span><br><span class="line">        trainModel()</span><br><span class="line">        acc = testModel()</span><br><span class="line">        acc_list.append((acc))</span><br><span class="line"></span><br><span class="line">    epoch = np.arange(1, len(acc_list) + 1, 1)</span><br><span class="line">    acc_list = np.array(acc_list)</span><br><span class="line">    plt.plot(epoch,acc_list)</span><br><span class="line">    plt.xlabel(&#x27;epoch&#x27;)</span><br><span class="line">    plt.ylabel(&#x27;acc&#x27;)</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>



<h2 id="应用-1"><a href="#应用-1" class="headerlink" title="应用"></a>应用</h2><p>rnn主要应用于序列问题</p>
<p>最常用的如自然语言处理</p>
<p>狗屁不通文章生成器就是如此</p>
<p>其中为了不让每次文章都一样，采用了重要性采样</p>
<p><strong>即不是每次的输出都采用概率最大的那个，而是根据概率随机采样，即概率越大输出的可能性越大</strong></p>
</div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="打赏" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="reward-comment">I'm so cute. Please give me money.</div><div id="qr" style="display:none;"><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/alipay-qrcode.jpg"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/alipay-qrcode.jpg" alt="支付宝" title="支付宝"></a><div><span style="color:#00A3EE"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/qqpay-qrcode.png"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/qqpay-qrcode.png" alt="QQ 支付" title="QQ 支付"></a><div><span style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></span></div></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/wechatpay-qrcode.jpg"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/wechatpay-qrcode.jpg" alt="微信支付" title="微信支付"></a><div><span style="color:#2DC100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>Vayne</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="http://example.com/2022/07/19/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/" title="pytorch深度学习实践">http://example.com/2022/07/19/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2022/07/28/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E2%80%94%E9%83%9D%E6%96%8C/" rel="prev" title="数据结构—郝斌"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">数据结构—郝斌</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2022/07/07/MySQL%E5%9F%BA%E7%A1%80/" rel="next" title="MySQL基础"><span class="post-nav-text">MySQL基础</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div class="hty-card" id="comment"><div class="comment-tooltip text-center"><span>要不要和我说些什么？</span><br></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2023 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> Vayne</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v5.4.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.6.2</span></div></footer><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a></div></body></html>