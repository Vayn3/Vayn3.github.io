<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="Vayne"><meta name="copyright" content="Vayne"><meta name="generator" content="Hexo 5.4.0"><meta name="theme" content="hexo-theme-yun"><title>pytorch入门笔记（土堆） | Yun</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.25/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_dxory92pb0h.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link rel="icon" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"hostname":"example.com","root":"/","title":["V","a","y","n","e"],"version":"1.6.2","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"搜索...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）"},"anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/utils.js"></script><script src="/js/hexo-theme-yun.js"></script><meta name="description" content="[TOC] 1.一些基本概念常用的两个函数dir()和help()  pytorch加载数据简介(dataset和dataloader)  Dataset类：读取数据集源码12345678910111213class Dataset(object):&quot;&quot;&quot;An abstract class representing a Dataset.All other datase">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch入门笔记（土堆）">
<meta property="og:url" content="http://example.com/2021/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%9F%E5%A0%86/index.html">
<meta property="og:site_name" content="Yun">
<meta property="og:description" content="[TOC] 1.一些基本概念常用的两个函数dir()和help()  pytorch加载数据简介(dataset和dataloader)  Dataset类：读取数据集源码12345678910111213class Dataset(object):&quot;&quot;&quot;An abstract class representing a Dataset.All other datase">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202112051715582.png">
<meta property="og:image" content="https://raw.githubusercontent.com/csrookie1/image/main/img/202111180022175.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202201032005291.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403060143828.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403060236998.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061612846.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202201032035993.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061626537.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061710186.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061937127.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061927541.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061943216.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061911874.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403071918812.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403071958448.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403072002830.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403072002465.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403072018464.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403081719132.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403081906613.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403081907953.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403081948452.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403081940066.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403081940058.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403091534370.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101513636.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101517486.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101536199.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101546069.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101557364.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101559430.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101600342.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101626048.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403102010005.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101949388.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403102029233.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403102029122.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403111550867.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403111809239.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403260134218.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403111759033.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403111802817.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403111805088.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403111913999.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403221514828.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403221513811.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403221516401.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403221516891.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403221516660.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202404271728441.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202404271727216.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202404271727985.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202404241654279.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202404241654490.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202404241655505.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403301806618.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202403260117645.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202405021613845.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202405021613582.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202405021440393.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202405021441691.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202404141716437.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202404141717291.png">
<meta property="article:published_time" content="2021-12-05T09:13:35.000Z">
<meta property="article:modified_time" content="2024-05-05T10:17:05.230Z">
<meta property="article:author" content="Vayne">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Vayn3/image/main/img/202112051715582.png"><script src="/js/ui/mode.js"></script></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="Vayne"><img width="96" loading="lazy" src="/images/touxiang.jpg" alt="Vayne"></a><div class="site-author-name"><a href="/about/">Vayne</a></div><span class="site-name">Yun</span><sub class="site-subtitle"></sub><div class="site-desciption">Blog</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">36</span></a></div><div class="site-state-item"><a href="/categories/" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">7</span></a></div><div class="site-state-item"><a href="/tags/" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">17</span></a></div><a class="site-state-item hty-icon-button" target="_blank" rel="noopener" href="https://yun.yunyoujun.cn" title="文档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-settings-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://qm.qq.com/cgi-bin/qm/qr?k=kZJzggTTCf4SpvEQ8lXWoi5ZjhAx0ILZ&amp;jump_from=webapi" title="QQ 群 1050458482" target="_blank" style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/YunYouJun" title="GitHub" target="_blank" style="color:#6e5494"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://weibo.com/jizhideyunyoujun" title="微博" target="_blank" style="color:#E6162D"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-weibo-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.douban.com/people/yunyoujun/" title="豆瓣" target="_blank" style="color:#007722"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-douban-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://music.163.com/#/user/home?id=247102977" title="网易云音乐" target="_blank" style="color:#C20C0C"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-netease-cloud-music-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.zhihu.com/people/yunyoujun/" title="知乎" target="_blank" style="color:#0084FF"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhihu-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/1579790" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/about/white-qrcode-and-search.jpg" title="微信公众号" target="_blank" style="color:#1AAD19"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-2-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://twitter.com/YunYouJun" title="Twitter" target="_blank" style="color:#1da1f2"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-twitter-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://t.me/elpsycn" title="Telegram Channel" target="_blank" style="color:#0088CC"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-telegram-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:me@yunyoujun.cn" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://travellings.link" title="Travelling" target="_blank" style="color:var(--hty-text-color)"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-train-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="我的小伙伴们" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E4%B8%80%E4%BA%9B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">1.</span> <span class="toc-text">1.一些基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E4%B8%A4%E4%B8%AA%E5%87%BD%E6%95%B0dir-%E5%92%8Chelp"><span class="toc-number">1.1.</span> <span class="toc-text">常用的两个函数dir()和help()</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#pytorch%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E7%AE%80%E4%BB%8B-dataset%E5%92%8Cdataloader"><span class="toc-number">2.</span> <span class="toc-text">pytorch加载数据简介(dataset和dataloader)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Dataset%E7%B1%BB%EF%BC%9A%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.</span> <span class="toc-text">Dataset类：读取数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%BA%90%E7%A0%81"><span class="toc-number">3.1.</span> <span class="toc-text">源码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%88%B6%E4%BD%9C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B4%A2%E5%BC%95"><span class="toc-number">3.2.</span> <span class="toc-text">1.制作图片数据的索引</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%9E%84%E5%BB%BADataset%E5%AD%90%E7%B1%BB"><span class="toc-number">3.3.</span> <span class="toc-text">2.构建Dataset子类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%EF%BC%9A%E8%9A%82%E8%9A%81%E5%92%8C%E8%9C%82%EF%BC%88%E5%9B%BE%E7%89%87%E5%92%8C%E6%A0%87%E7%AD%BE%E5%88%86%E5%BC%80%E5%AD%98%E6%94%BE%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%89"><span class="toc-number">3.4.</span> <span class="toc-text">案例：蚂蚁和蜂（图片和标签分开存放的数据集）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E6%9E%9C%E6%98%AFtxt%E4%BD%9Clabel%E7%9A%84"><span class="toc-number">3.4.1.</span> <span class="toc-text">如果是txt作label的</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#tensorboard%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">4.</span> <span class="toc-text">tensorboard的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8D%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98"><span class="toc-number">4.1.</span> <span class="toc-text">不显示问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#summarywriter%E7%B1%BB"><span class="toc-number">4.2.</span> <span class="toc-text">summarywriter类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#add-scalar-%E7%94%A8%E6%B3%95"><span class="toc-number">4.3.</span> <span class="toc-text">add_scalar()用法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#add-image-%E7%94%A8%E6%B3%95"><span class="toc-number">4.4.</span> <span class="toc-text">add_image()用法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BD%AC%E6%8D%A2%E6%88%90numpy%E5%9E%8B"><span class="toc-number">4.4.1.</span> <span class="toc-text">转换成numpy型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#transforms%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">5.</span> <span class="toc-text">transforms的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E8%A6%81%E7%B1%BB"><span class="toc-number">5.1.</span> <span class="toc-text">重要类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#call%E5%87%BD%E6%95%B0"><span class="toc-number">5.2.</span> <span class="toc-text">call函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#transform%E3%80%81datasets-tensorbord%E8%81%94%E5%90%88"><span class="toc-number">5.3.</span> <span class="toc-text">transform、datasets tensorbord联合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dataloader"><span class="toc-number">5.4.</span> <span class="toc-text">dataloader</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C"><span class="toc-number">6.</span> <span class="toc-text">卷积网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E9%AA%A8%E6%9E%B6-nn-Module"><span class="toc-number">6.1.</span> <span class="toc-text">神经网络基本骨架-nn.Module</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-1"><span class="toc-number">6.2.</span> <span class="toc-text">卷积网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#conv2d"><span class="toc-number">6.2.1.</span> <span class="toc-text">conv2d</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%EF%BC%9A%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E5%8D%B7%E7%A7%AF%E5%90%8E%E7%9A%84%E5%B0%BA%E5%AF%B8"><span class="toc-number">6.2.2.</span> <span class="toc-text">应用：如何查看卷积后的尺寸</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96MaxPool2d"><span class="toc-number">6.2.3.</span> <span class="toc-text">最大池化MaxPool2d</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%EF%BC%9A%E6%A0%B9%E6%8D%AE%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AE%A1%E7%AE%97%E5%8F%82%E6%95%B0"><span class="toc-number">6.3.</span> <span class="toc-text">应用：根据网络结构计算参数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">6.3.1.</span> <span class="toc-text">代码实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96%EF%BC%9Aadd-graph"><span class="toc-number">6.3.1.1.</span> <span class="toc-text">可视化：add_graph</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E3%80%81%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E3%80%81%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">6.4.</span> <span class="toc-text">损失函数、反向传播、优化器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E7%86%B5"><span class="toc-number">6.4.1.</span> <span class="toc-text">交叉熵</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%9A%E5%88%A9%E7%94%A8backward%E5%87%BD%E6%95%B0%E6%B1%82%E5%87%BA%E6%A2%AF%E5%BA%A6"><span class="toc-number">6.4.1.1.</span> <span class="toc-text">反向传播：利用backward函数求出梯度</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E7%8E%B0%E6%88%90%E7%9A%84%E7%BD%91%E7%BB%9C%EF%BC%88%E4%BF%AE%E6%94%B9%E4%B8%80%E4%BA%9B%E5%8F%82%E6%95%B0%EF%BC%89"><span class="toc-number">6.5.</span> <span class="toc-text">如何利用现成的网络（修改一些参数）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#vgg16"><span class="toc-number">6.5.1.</span> <span class="toc-text">vgg16</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%AF%BB%E5%8F%96"><span class="toc-number">6.6.</span> <span class="toc-text">模型保存与读取</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%E5%8F%82%E6%95%B0%E5%AD%97%E5%85%B8"><span class="toc-number">6.6.1.</span> <span class="toc-text">保存参数字典</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E5%87%86%E7%A1%AE%E7%8E%87"><span class="toc-number">6.7.</span> <span class="toc-text">分类问题准确率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GPU%E8%AE%AD%E7%BB%83"><span class="toc-number">6.8.</span> <span class="toc-text">GPU训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E5%BB%BA%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E5%A5%97%E8%B7%AF"><span class="toc-number">6.9.</span> <span class="toc-text">自建网络训练套路</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%A5%97%E8%B7%AF%EF%BC%88%E5%8D%B3%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E7%8E%AF%E5%A2%83%EF%BC%89"><span class="toc-number">6.10.</span> <span class="toc-text">利用训练好的模型套路（即实际应用环境）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96%E8%BE%93%E5%87%BA"><span class="toc-number">6.10.1.</span> <span class="toc-text">可视化输出</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#github%E5%AF%BB%E6%89%BE%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">6.11.</span> <span class="toc-text">github寻找开源项目注意事项</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%8C%E6%88%90%E9%A1%B9%E7%9B%AE"><span class="toc-number">7.</span> <span class="toc-text">完成项目</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A9%E6%B0%94%E5%88%86%E7%B1%BB"><span class="toc-number">7.1.</span> <span class="toc-text">天气分类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-number">7.1.1.</span> <span class="toc-text">数据处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#dataframe-json%E6%93%8D%E4%BD%9C"><span class="toc-number">7.1.1.1.</span> <span class="toc-text">dataframe json操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%86%E5%88%AB%E9%80%9A%E9%81%93%E4%B8%8D%E4%B8%BA3%E7%9A%84"><span class="toc-number">7.1.1.2.</span> <span class="toc-text">识别通道不为3的</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96"><span class="toc-number">7.1.2.</span> <span class="toc-text">优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96%E6%A8%A1%E5%9E%8B%EF%BC%8C%E9%9A%8F%E4%BE%BF%E5%8F%96%E5%BC%A0%E5%9B%BE%E7%89%87%E6%9D%A5%E9%A2%84%E6%B5%8B"><span class="toc-number">7.1.3.</span> <span class="toc-text">读取模型，随便取张图片来预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E6%80%BB%E7%BB%93"><span class="toc-number">7.1.4.</span> <span class="toc-text">参数总结</span></a></li></ol></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://example.com/2021/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%9F%E5%A0%86/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="Vayne"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="Yun"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">pytorch入门笔记（土堆）</h1><div class="post-meta"><div class="post-time" style="display:inline-block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2021-12-05 17:13:35" itemprop="dateCreated datePublished" datetime="2021-12-05T17:13:35+08:00">2021-12-05</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-2-line"></use></svg></span> <time title="修改时间：2024-05-05 18:17:05" itemprop="dateModified" datetime="2024-05-05T18:17:05+08:00">2024-05-05</time></div><div class="post-classify"><span class="post-category"> <span class="post-meta-item-icon" style="margin-right:3px;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">深度学习</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag-item" href="/tags/pytorch/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">pytorch</span></a></span></div><div class="post-author"><span class="author-name">Vayne</span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#0078E7;"><p>[TOC]</p>
<h1 id="1-一些基本概念"><a href="#1-一些基本概念" class="headerlink" title="1.一些基本概念"></a>1.一些基本概念</h1><h2 id="常用的两个函数dir-和help"><a href="#常用的两个函数dir-和help" class="headerlink" title="常用的两个函数dir()和help()"></a>常用的两个函数dir()和help()</h2><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202112051715582.png" alt="image-20211117224635582" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/csrookie1/image/main/img/202111180022175.png" alt="image-20211118002242936" loading="lazy"></p>
<h1 id="pytorch加载数据简介-dataset和dataloader"><a href="#pytorch加载数据简介-dataset和dataloader" class="headerlink" title="pytorch加载数据简介(dataset和dataloader)"></a>pytorch加载数据简介(dataset和dataloader)</h1><p> <img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202201032005291.png" alt="image-20220103200507182" loading="lazy"></p>
<h1 id="Dataset类：读取数据集"><a href="#Dataset类：读取数据集" class="headerlink" title="Dataset类：读取数据集"></a>Dataset类：读取数据集</h1><h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dataset</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;An abstract class representing a Dataset.</span></span><br><span class="line"><span class="string">All other datasets should subclass it. All subclasses should override</span></span><br><span class="line"><span class="string">``__len__``, that provides the size of the dataset, and ``__getitem__``,</span></span><br><span class="line"><span class="string">supporting integer indexing in range from 0 to len(self) exclusive.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">	<span class="keyword">raise</span> NotImplementedError</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">	<span class="keyword">raise</span> NotImplementedError</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__add__</span>(<span class="params">self, other</span>):</span></span><br><span class="line">	<span class="keyword">return</span> ConcatDataset([self, other])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>重点是getitem函数：</p>
<p>getitem接收一个index，然后返回图片数据和标签，这个index通常指的是一个list的index，这个list的每个元素就包含了图片数据的路径和标签信息。</p>
<p>然而，如何制作这个list呢，通常的方法是将图片的路径和标签信息存储在一个txt中，然后从该txt中读取。<br>那么读取自己数据的基本流程就是：</p>
<p>1.制作存储了图片的路径和标签信息的txt<br>2.将这些信息转化为list，该list每一个元素对应一个样本<br>3.通过getitem函数，读取数据和标签，并返回数据和标签</p>
<p>要让PyTorch能读取自己的数据集，只需要两步：</p>
<h2 id="1-制作图片数据的索引"><a href="#1-制作图片数据的索引" class="headerlink" title="1.制作图片数据的索引"></a>1.制作图片数据的索引</h2><p>这个比较简单，就是读取图片路径，标签，保存到txt文件中，这里注意格式就好<br>特别注意的是，txt中的路径，是以训练时的那个py文件所在的目录为工作目录，所以这里需要提前算好相对路径</p>
<h2 id="2-构建Dataset子类"><a href="#2-构建Dataset子类" class="headerlink" title="2.构建Dataset子类"></a>2.构建Dataset子类</h2><p>例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, txt_path, transform = <span class="literal">None</span>, target_transform = <span class="literal">None</span></span>):</span></span><br><span class="line">	fh = <span class="built_in">open</span>(txt_path, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">	imgs = []</span><br><span class="line">	<span class="keyword">for</span> line <span class="keyword">in</span> fh:</span><br><span class="line">		line = line.rstrip()</span><br><span class="line">		words = line.split()</span><br><span class="line">		imgs.append((words[<span class="number">0</span>], <span class="built_in">int</span>(words[<span class="number">1</span>])))</span><br><span class="line">		self.imgs = imgs </span><br><span class="line">		self.transform = transform</span><br><span class="line">		self.target_transform = target_transform</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">	fn, label = self.imgs[index]</span><br><span class="line">	img = Image.<span class="built_in">open</span>(fn).convert(<span class="string">&#x27;RGB&#x27;</span>) </span><br><span class="line">	<span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">		img = self.transform(img) </span><br><span class="line">	<span class="keyword">return</span> img, label</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">len</span>(self.imgs)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>总结：getitem函数用来读取图片数据的索引，然后在transform里进行处理</p>
<h2 id="案例：蚂蚁和蜂（图片和标签分开存放的数据集）"><a href="#案例：蚂蚁和蜂（图片和标签分开存放的数据集）" class="headerlink" title="案例：蚂蚁和蜂（图片和标签分开存放的数据集）"></a>案例：蚂蚁和蜂（图片和标签分开存放的数据集）</h2><p>先处理数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from PIL import Image</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">img_path = &quot;download.pytorch.org_032250//hymenoptera_data//train//ants//0013035.jpg&quot; </span><br><span class="line">img = Image.open(img_path)</span><br><span class="line">img.show()</span><br><span class="line">dir_path = &quot;download.pytorch.org_032250/hymenoptera_data/train/ants&quot;</span><br><span class="line">img_path_list = os.listdir(dir_path) #建立一个图片列表方便读取下标</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403060143828.png" alt="image-20240306014352750" loading="lazy"></p>
<p>构造dataset</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyData</span>(<span class="params">Dataset</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, root_dir, label_dir</span>):</span></span><br><span class="line">        self.root_dir = root_dir <span class="comment">#根地址</span></span><br><span class="line">        self.label_dir = label_dir <span class="comment">#标签地址</span></span><br><span class="line">        self.path = os.path.join(self.root_dir, self.label_dir) <span class="comment">#地址拼凑</span></span><br><span class="line">        self.img_path = os.listdir(self.path) <span class="comment">#构造图片列表</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        img_name = self.img_path[idx]  <span class="comment">#根据下标得到图片的文件名</span></span><br><span class="line">        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name) <span class="comment">#得到相对路径</span></span><br><span class="line">        img = Image.<span class="built_in">open</span>(img_item_path) <span class="comment">#得到图片</span></span><br><span class="line">        label = self.label_dir</span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_path) <span class="comment">#返回列表长度</span></span><br></pre></td></tr></table></figure>

<p>实例化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root_dir = &quot;download.pytorch.org_032250/hymenoptera_data/train&quot;</span><br><span class="line">ants_label_dir = &quot;ants&quot;</span><br><span class="line">bees_label_dir = &quot;bees&quot;</span><br><span class="line">ants_dataset = MyData(root_dir, ants_label_dir)</span><br><span class="line">bees_dataset = MyData(root_dir, bees_label_dir)</span><br><span class="line"></span><br><span class="line">#完整的数据集应当是二者合一</span><br><span class="line">train_dataset = ants_dataset + bees_dataset</span><br></pre></td></tr></table></figure>

<h3 id="如果是txt作label的"><a href="#如果是txt作label的" class="headerlink" title="如果是txt作label的"></a>如果是txt作label的</h3><p>如何利用先前的数据集构造的：<strong>把图片的label 生成以图片名为文件名的txt文档</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403060236998.png" alt="image-20240306023607937" loading="lazy"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line"></span><br><span class="line">root_dir = &#x27;练手数据集/train&#x27;</span><br><span class="line">target_dir = &#x27;ants_image&#x27;</span><br><span class="line">img_path = os.listdir(os.path.join(root_dir, target_dir))</span><br><span class="line">label = target_dir.split(&#x27;_&#x27;)【0】</span><br><span class="line">out_dir = &#x27;ants_label&#x27;</span><br><span class="line">for i in img_path:</span><br><span class="line">    file_name = i.split(&#x27;.jpg&#x27;)【0】</span><br><span class="line">    with open(os.path.join(root_dir, out_dir,&quot;&#123;&#125;.txt&quot;.format(file_name)),&#x27;w&#x27;) as f:</span><br><span class="line">        f.write(label)</span><br></pre></td></tr></table></figure>



<h1 id="tensorboard的使用"><a href="#tensorboard的使用" class="headerlink" title="tensorboard的使用"></a>tensorboard的使用</h1><h2 id="不显示问题"><a href="#不显示问题" class="headerlink" title="不显示问题"></a>不显示问题</h2><p>需要命令行cd到当前目录行</p>
<p>可视化工具</p>
<h2 id="summarywriter类"><a href="#summarywriter类" class="headerlink" title="summarywriter类"></a>summarywriter类</h2><p>常用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>运行完后会在当前文件夹目录下多出一个名为logs的文件</p>
<h2 id="add-scalar-用法"><a href="#add-scalar-用法" class="headerlink" title="add_scalar()用法"></a>add_scalar()用法</h2><p>作用：添加标量数据给summary类</p>
<p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">add_scalar(</span><br><span class="line">    self,</span><br><span class="line">    tag,<span class="comment">#标题</span></span><br><span class="line">    scalar_value, <span class="comment"># y轴</span></span><br><span class="line">    global_step=<span class="literal">None</span>, <span class="comment"># x轴</span></span><br><span class="line">    walltime=<span class="literal">None</span>,</span><br><span class="line">    new_style=<span class="literal">False</span>,</span><br><span class="line">    double_precision=<span class="literal">False</span>,</span><br><span class="line">)：</span><br></pre></td></tr></table></figure>

<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">writer.add_scalar(<span class="string">&quot;y=x&quot;</span>, i, i)</span><br></pre></td></tr></table></figure>

<p>运行后产生一个logs的文件夹,然后在终端输入：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=logs </span><br></pre></td></tr></table></figure>

<p>logdir=(事件文件名)</p>
<h2 id="add-image-用法"><a href="#add-image-用法" class="headerlink" title="add_image()用法"></a>add_image()用法</h2><p>作用：添加图像数据给summary类</p>
<p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">add_image(self, </span><br><span class="line">          tag,<span class="comment">#标题</span></span><br><span class="line">          img_tensor,<span class="comment">#图形的数据类型 </span></span><br><span class="line">          global_step=<span class="literal">None</span>, <span class="comment">#第几个步骤</span></span><br><span class="line">          walltime=<span class="literal">None</span>, </span><br><span class="line">          dataformats=<span class="string">&#x27;CHW&#x27;</span><span class="comment">#形状，c为通道 h为高 w为宽 当格式不匹配时会报错，需要加上这个参数来修改):</span></span><br></pre></td></tr></table></figure>

<p>正常的jpg图片类型需要转换成tensor或者numpy才行</p>
<h3 id="转换成numpy型"><a href="#转换成numpy型" class="headerlink" title="转换成numpy型"></a>转换成numpy型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image_array = np.array(img)</span><br></pre></td></tr></table></figure>

<p>实例：打开图片 查看尺寸 转换格式 add_image （然后就可在tb里看到图形）</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061612846.png" alt="image-20240306161234721" loading="lazy"></p>
<h1 id="transforms的使用"><a href="#transforms的使用" class="headerlink" title="transforms的使用"></a>transforms的使用</h1><p>作用:<strong>处理图片</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202201032035993.png" alt="image-20220103203549896" loading="lazy"></p>
<h2 id="重要类"><a href="#重要类" class="headerlink" title="重要类"></a>重要类</h2><p><strong>Compose类</strong></p>
<p>将要进行的transform操作集合起来一步步进行</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061626537.png" alt="image-20240306162632462" loading="lazy"></p>
<p><strong>ToTensor</strong></p>
<p>使用对象必须是PIL Image 、numpy.ndarray</p>
<p><strong>1.用Image.open 读入jpg</strong></p>
<p><strong>2.用cv2.imread读入（转换成numpy）</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061710186.png" alt="image-20240306171022112" loading="lazy"></p>
<p><strong>resize 按比例缩放一个img</strong></p>
<p> <img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061937127.png" alt="image-20240306193745057" loading="lazy"></p>
<p><strong>Normalize 对tensor归一化（可以指定均值和方差）</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061927541.png" alt="image-20240306192756471" loading="lazy"></p>
<p><strong>RandomCrop 随机裁剪一个img</strong></p>
<p>学习的点：用Compose先裁剪再totensor 连续十次 并加入到tb上</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061943216.png" alt="image-20240306194329131" loading="lazy"></p>
<p><strong>为什么用tensor数据类型</strong></p>
<p>用法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">img_path = <span class="string">&quot;data/train/ants_image/0013035.jpg&quot;</span></span><br><span class="line">img_PIL = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line"></span><br><span class="line">tensor_trans = transforms.ToTensor()</span><br><span class="line">tensor_img = tensor_trans(img_PIL)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tensor_img)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="call函数"><a href="#call函数" class="headerlink" title="call函数"></a>call函数</h2><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403061911874.png" alt="image-20240306191130741" loading="lazy"></p>
<p>即可不用.hello的形式调用方法  可以自动调用</p>
<h2 id="transform、datasets-tensorbord联合"><a href="#transform、datasets-tensorbord联合" class="headerlink" title="transform、datasets tensorbord联合"></a>transform、datasets tensorbord联合</h2><p>datasets主要提供一些常用数据集</p>
<p>先transform 在datasets</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403071918812.png" alt="image-20240307191809628" loading="lazy"></p>
<h2 id="dataloader"><a href="#dataloader" class="headerlink" title="dataloader"></a>dataloader</h2><p>每次取一个batch_size的数据打包返回</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403071958448.png" alt="image-20240307195820359" loading="lazy"></p>
<p>代码示例</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403072002830.png" alt="image-20240307200215707" loading="lazy"></p>
<p>结果：可以看出 一个data打包了四份</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403072002465.png" alt="image-20240307200254368" loading="lazy"></p>
<p>将dataloader每个batch送入tb里观察</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403072018464.png" alt="image-20240307201820362" loading="lazy"></p>
<h1 id="卷积网络"><a href="#卷积网络" class="headerlink" title="卷积网络"></a>卷积网络</h1><h2 id="神经网络基本骨架-nn-Module"><a href="#神经网络基本骨架-nn-Module" class="headerlink" title="神经网络基本骨架-nn.Module"></a>神经网络基本骨架-nn.Module</h2><p>一个简单的例子</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403081719132.png" alt="image-20240308171931943" loading="lazy"></p>
<h2 id="卷积网络-1"><a href="#卷积网络-1" class="headerlink" title="卷积网络"></a>卷积网络</h2><h3 id="conv2d"><a href="#conv2d" class="headerlink" title="conv2d"></a>conv2d</h3><p>2d指二维图像 参数为：</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403081906613.png" alt="image-20240308190633540" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403081907953.png" alt="image-20240308190704852" loading="lazy"></p>
<p><strong>尺寸推导</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403081948452.png" alt="image-20240308194836370" loading="lazy"></p>
<h3 id="应用：如何查看卷积后的尺寸"><a href="#应用：如何查看卷积后的尺寸" class="headerlink" title="应用：如何查看卷积后的尺寸"></a>应用：如何查看卷积后的尺寸</h3><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403081940066.png" alt="image-20240308194042940" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403081940058.png" alt="image-20240308194056986" loading="lazy"></p>
<p><strong>实际应用：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Net(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(3, 10, kernel_size=5)  # 卷积层</span><br><span class="line">        self.pooling = torch.nn.MaxPool2d(2)  # 池化层</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5)</span><br><span class="line">        # self.fc1 = torch.nn.Linear(74420, 100) #可以随便填一个数，等报错后即可看到卷积层尺寸</span><br><span class="line">        # self.fc2 = torch.nn.Linear(100, 3)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        batch_size = x.size(0)</span><br><span class="line">        x = F.relu(self.pooling(self.conv1(x)))  #</span><br><span class="line">        x = F.relu(self.pooling(self.conv2(x)))</span><br><span class="line">        x = x.view(batch_size, -1)  # 变为64*？ 由计算机算出</span><br><span class="line">        # x = F.relu(self.fc1(x))</span><br><span class="line">        # x = self.fc2(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 在main函数中测试模型正确性</span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    model = Net()</span><br><span class="line">    input = torch.ones(64, 3, 128, 128)</span><br><span class="line">    output = model(input)</span><br><span class="line">    print(output.shape)</span><br></pre></td></tr></table></figure>



<h3 id="最大池化MaxPool2d"><a href="#最大池化MaxPool2d" class="headerlink" title="最大池化MaxPool2d"></a>最大池化MaxPool2d</h3><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403091534370.png" alt="image-20240309153432207" loading="lazy"></p>
<p>dilation参数：空洞卷积， 卷积核的每个格子间隔一个</p>
<p>注意区分add_image和add_images 后者传入的是四维（batchsize, c, w, h),即前者是一张图片，后者一组图片</p>
<h2 id="应用：根据网络结构计算参数"><a href="#应用：根据网络结构计算参数" class="headerlink" title="应用：根据网络结构计算参数"></a>应用：根据网络结构计算参数</h2><p>网络结构</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101513636.png" alt="image-20240310151346487" loading="lazy"></p>
<p>如何计算卷积参数？</p>
<p>  <img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101517486.png" alt="image-20240310151725366" loading="lazy"></p>
<p><strong>注意：dilation参数默认是1</strong></p>
<p><strong>快速方法：</strong></p>
<p>卷积核大小为3时，会消掉一圈，即32*32变为 31 * 31，此时设置padding为1则卷积操作前后尺寸保持不变</p>
<p>同理，卷积核大小5则会消掉两圈， padding要为2</p>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101536199.png" alt="image-20240310153650943" loading="lazy"></p>
<p>可以先用相同尺寸的全1数据对网络测试一下</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101546069.png" alt="image-20240310154602992" loading="lazy"></p>
<p>引入sequential 代码更加简洁</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101557364.png" alt="image-20240310155741294" loading="lazy"></p>
<h4 id="可视化：add-graph"><a href="#可视化：add-graph" class="headerlink" title="可视化：add_graph"></a>可视化：add_graph</h4><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101559430.png" alt="image-20240310155952372" loading="lazy"></p>
<p>可以显示计算图</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101600342.png" alt="image-20240310160026239" loading="lazy"></p>
<h2 id="损失函数、反向传播、优化器"><a href="#损失函数、反向传播、优化器" class="headerlink" title="损失函数、反向传播、优化器"></a>损失函数、反向传播、优化器</h2><h3 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h3><p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101626048.png" alt="image-20240310162654958" loading="lazy"></p>
<h4 id="反向传播：利用backward函数求出梯度"><a href="#反向传播：利用backward函数求出梯度" class="headerlink" title="反向传播：利用backward函数求出梯度"></a><strong>反向传播：利用backward函数求出梯度</strong></h4><p>注意 开始要清零上一个循环求出的梯度：zero_grad函数</p>
<h2 id="如何利用现成的网络（修改一些参数）"><a href="#如何利用现成的网络（修改一些参数）" class="headerlink" title="如何利用现成的网络（修改一些参数）"></a>如何利用现成的网络（修改一些参数）</h2><h3 id="vgg16"><a href="#vgg16" class="headerlink" title="vgg16"></a>vgg16</h3><p>下载</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403102010005.png" alt="image-20240310201040952" loading="lazy"></p>
<p>最后一层线性层参数不符</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403101949388.png" alt="image-20240310194940306" loading="lazy"></p>
<p>两种解决方法</p>
<p> <strong>1.再加一层线性层</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vgg16_true.classifier.add_module(&quot;add_linear&quot;,Linear(1000,10))</span><br></pre></td></tr></table></figure>

<p><strong>注意</strong></p>
<p>添加一层线性层后要保证forward时要调用</p>
<p>所以不如直接修改</p>
<p><strong>2.修改最后一层</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vgg16_false.classifier[6]=Linear(4096,10)</span><br></pre></td></tr></table></figure>



<h2 id="模型保存与读取"><a href="#模型保存与读取" class="headerlink" title="模型保存与读取"></a>模型保存与读取</h2><p><strong>保存</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403102029233.png" alt="image-20240310202904148" loading="lazy"></p>
<p>读取</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403102029122.png" alt="image-20240310202921038" loading="lazy"></p>
<p><strong>陷阱</strong></p>
<p>自定义类加载模型时，<strong>还是得把之前定义类的代码粘贴过来</strong></p>
<h3 id="保存参数字典"><a href="#保存参数字典" class="headerlink" title="保存参数字典"></a>保存参数字典</h3><p>保存的代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model.state_dict(), PATH)</span><br></pre></td></tr></table></figure>

<p>加载的代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = TheModelClass(*args, **kwargs)</span><br><span class="line">model.load_state_dict(torch.load(PATH))</span><br><span class="line">model.eval()</span><br></pre></td></tr></table></figure>

<p>记住</p>
<ol>
<li>在进行预测之前，必须调用 <code>model.eval()</code> 方法来将 <code>dropout</code> 和 <code>batch normalization</code> 层设置为验证模型。否则，只会生成前后不一致的预测结果。</li>
<li><code>load_state_dict()</code> 方法必须传入一个字典对象，而不是对象的保存路径，也就是说必须先反序列化字典对象，然后再调用该方法，也是例子中先采用 <code>torch.load()</code> ，而不是直接 <code>model.load_state_dict(PATH)</code></li>
</ol>
<h2 id="分类问题准确率"><a href="#分类问题准确率" class="headerlink" title="分类问题准确率"></a>分类问题准确率</h2><p>至此，output的输出格式为矩阵小数， 为了输出准确率，要转换成标签矩阵，和tagets进行对比</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403111550867.png" alt="image-20240311155021799" loading="lazy"></p>
<p>用argmax输出行最大的列号，即为标签值</p>
<h2 id="GPU训练"><a href="#GPU训练" class="headerlink" title="GPU训练"></a>GPU训练</h2><p>先判断</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">tudui.to(device)</span><br></pre></td></tr></table></figure>

<p>再把需要计算的数据全丢到gpu即可</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line">loss = loss.to(device)</span><br><span class="line"></span><br><span class="line">imgs, targets = imgs.to(device), targets.to(device)</span><br></pre></td></tr></table></figure>



<h2 id="自建网络训练套路"><a href="#自建网络训练套路" class="headerlink" title="自建网络训练套路"></a>自建网络训练套路</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.utils.data import DataLoader, dataloader</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line">import time</span><br><span class="line">from net1 import *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(&quot;data&quot;, train=True, download=True,</span><br><span class="line">                                       transform=torchvision.transforms.ToTensor())</span><br><span class="line">test_data = torchvision.datasets.CIFAR10(&quot;data&quot;, train=False, download=True,</span><br><span class="line">                                       transform=torchvision.transforms.ToTensor())</span><br><span class="line">#长度</span><br><span class="line">train_data_size = len(train_data)</span><br><span class="line">test_data_size = len(test_data)</span><br><span class="line">print(&quot;训练集长度:&#123;&#125;&quot;.format(train_data_size))</span><br><span class="line">print(&quot;测试集长度:&#123;&#125;&quot;.format(test_data_size))</span><br><span class="line"></span><br><span class="line">#加载</span><br><span class="line">train_dataloader = DataLoader(train_data, batch_size=64)</span><br><span class="line">test_dataloader = DataLoader(test_data, batch_size=64)</span><br><span class="line"></span><br><span class="line">#搭建网络 为了规范</span><br><span class="line">tudui = Tudui()</span><br><span class="line"></span><br><span class="line">#GPU</span><br><span class="line">device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">tudui.to(device)</span><br><span class="line"></span><br><span class="line">#损失和优化器</span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line">loss = loss.to(device)</span><br><span class="line">optim = torch.optim.SGD(tudui.parameters(), lr=0.01)</span><br><span class="line"></span><br><span class="line">#训练网络参数</span><br><span class="line">total_train_step = 0  #训练次数</span><br><span class="line">total_test_step = 0  #测试次数</span><br><span class="line">epoch = 10 #训练轮数</span><br><span class="line"></span><br><span class="line">#tb可视化</span><br><span class="line">writer = SummaryWriter(&quot;logs_train&quot;)</span><br><span class="line"></span><br><span class="line">#计时开始</span><br><span class="line">start_time = time.time()</span><br><span class="line"></span><br><span class="line">for i in range(epoch):</span><br><span class="line">    print(&quot;-------第&#123;&#125;轮训练-------&quot;.format(i+1))</span><br><span class="line"></span><br><span class="line">    #训练</span><br><span class="line">    for data in train_dataloader:</span><br><span class="line">        imgs, targets = data</span><br><span class="line">        imgs, targets = imgs.to(device), targets.to(device)</span><br><span class="line">        outputs = tudui(imgs)</span><br><span class="line">        train_loss = loss(outputs, targets)</span><br><span class="line"></span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        train_loss.backward() #求得梯度</span><br><span class="line">        optim.step()</span><br><span class="line">        total_train_step = total_train_step + 1</span><br><span class="line">        if total_train_step % 200 == 0:</span><br><span class="line">            #计时结束</span><br><span class="line">            end_time = time.time()</span><br><span class="line">            print(end_time - start_time)</span><br><span class="line"></span><br><span class="line">            print(&quot;训练次数：&#123;&#125;， Loss:&#123;&#125;&quot;.format(total_train_step, train_loss.item())) #item将tensor转换成数字</span><br><span class="line">            writer.add_scalar(&quot;train_loss&quot;, train_loss.item(), total_train_step) #tb图像</span><br><span class="line"></span><br><span class="line">    #测试</span><br><span class="line">    total_test_loss = 0</span><br><span class="line">    total_acc = 0;</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for data in test_dataloader:</span><br><span class="line">            imgs, targets = data</span><br><span class="line">            imgs, targets = imgs.to(device), targets.to(device)</span><br><span class="line">            outputs = tudui(imgs)</span><br><span class="line">            test_loss = loss(outputs, targets)</span><br><span class="line">            total_test_loss = total_test_loss + test_loss.item()</span><br><span class="line">            acc = (outputs.argmax(1) == targets).sum() #布尔矩阵里的1个数，即为预测准确的个数</span><br><span class="line">            total_acc = total_acc + acc</span><br><span class="line"></span><br><span class="line">    #tb可视</span><br><span class="line">    print(&quot;这一轮整体测试集loss：&#123;&#125;&quot;.format(total_test_loss))</span><br><span class="line">    print(&quot;这一轮整体测试集acc: &#123;:.2%&#125;&quot;.format(total_acc/test_data_size)) #准确率=预测正确个数/总的个数 并以％形式输出</span><br><span class="line">    writer.add_scalar(&quot;test_loss&quot;, total_test_loss, total_test_step)</span><br><span class="line">    writer.add_scalar(&quot;test_acc&quot;, total_acc/test_data_size, total_test_step)</span><br><span class="line">    total_test_step = total_test_step + 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #保存模型</span><br><span class="line">    #torch.save(tudui.state_dict(), &quot;tudui_&#123;&#125;.pth&quot;.format(i))</span><br><span class="line">    #print(&quot;模型已保存&quot;)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>





<h2 id="利用训练好的模型套路（即实际应用环境）"><a href="#利用训练好的模型套路（即实际应用环境）" class="headerlink" title="利用训练好的模型套路（即实际应用环境）"></a>利用训练好的模型套路（即实际应用环境）</h2><p><strong>注意：png保存的图片可能是四个通道，要转换一下</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403111809239.png" alt="image-20240311180955057" loading="lazy"></p>
<p><strong>处理数据</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403260134218.png" alt="image-20240326013417144" loading="lazy"></p>
<p>将原本训练好的模型保存， 然后加载</p>
<p> 注意：要把网络结构也复制过来</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403111759033.png" alt="image-20240311175929927" loading="lazy"></p>
<p>发现报错 需要输入四个维度， 但image只有三个</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403111802817.png" alt="image-20240311180219618" loading="lazy"></p>
<p>可以用colab训练很多轮后下载训练好的模型来用</p>
<p><strong>注意：gpu训练的模型要加参数改到cpu上用</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403111805088.png" alt="image-20240311180515977" loading="lazy"></p>
<h3 id="可视化输出"><a href="#可视化输出" class="headerlink" title="可视化输出"></a>可视化输出</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">weather_dict = &#123;</span><br><span class="line">    0: &quot;cloudy&quot;,</span><br><span class="line">    1: &quot;foggy&quot;,</span><br><span class="line">    2: &quot;rainy&quot;,</span><br><span class="line">    3: &quot;shine&quot;,</span><br><span class="line">    4: &quot;snowy&quot;,</span><br><span class="line">    5: &quot;sunrise&quot;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#预测</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    output = model(image)</span><br><span class="line">print(output)</span><br><span class="line">index = output.argmax(1).item()</span><br><span class="line"></span><br><span class="line">#可视化</span><br><span class="line">print(weather_dict[index])</span><br><span class="line">img.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h2 id="github寻找开源项目注意事项"><a href="#github寻找开源项目注意事项" class="headerlink" title="github寻找开源项目注意事项"></a>github寻找开源项目注意事项</h2><p>注意寻找代码结构熟悉的</p>
<p>下载代码后，记得把需要输入的参数（required=True）改为默认（default=）</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403111913999.png" alt="image-20240311191305834" loading="lazy"></p>
<p>–dataroot 表面这是一个参数</p>
<p>后面紧跟的就是路径</p>
<h1 id="完成项目"><a href="#完成项目" class="headerlink" title="完成项目"></a>完成项目</h1><h2 id="天气分类"><a href="#天气分类" class="headerlink" title="天气分类"></a>天气分类</h2><p><strong>数据集</strong></p>
<p>共六类 4200张照片左右</p>
<p>五百张测试集</p>
<h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><p><strong>目标：将对应天气的图片放入对应文件夹</strong></p>
<h4 id="dataframe-json操作"><a href="#dataframe-json操作" class="headerlink" title="dataframe json操作"></a>dataframe json操作</h4><p><strong>获取某一行</strong></p>
<p>在pandas库中，如果你想要获取DataFrame中的某一行，你可以使用<code>.loc[]</code>或<code>.iloc[]</code>方法。这两种方法分别基于标签和基于整数位置来索引行。</p>
<p><strong>获取长度</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(train_json)</span><br></pre></td></tr></table></figure>



<p><strong>复制文件</strong></p>
<p>在Python中，你可以使用<code>shutil</code>库中的<code>copy()</code>或<code>copy2()</code>函数来复制文件。这些函数可以将一个文件从一个位置复制到另一个位置。</p>
<p>以下是一个包含这些步骤的完整示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import shutil</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"># 源文件路径</span><br><span class="line">source_file = &#x27;/path/to/source/file.txt&#x27;</span><br><span class="line"></span><br><span class="line"># 目标文件夹路径</span><br><span class="line">target_directory = &#x27;/path/to/target/directory&#x27;</span><br><span class="line"></span><br><span class="line"># 检查目标文件夹是否存在，如果不存在则创建</span><br><span class="line">if not os.path.exists(target_directory):</span><br><span class="line">    os.makedirs(target_directory)</span><br><span class="line"></span><br><span class="line"># 使用shutil的copy2函数复制文件</span><br><span class="line">shutil.copy2(source_file, target_directory)</span><br></pre></td></tr></table></figure>

<p>这个示例首先检查目标文件夹是否存在，如果不存在，它将创建文件夹，然后使用<code>shutil.copy2()</code>函数将文件复制到目标文件夹中。</p>
<p>应用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import shutil</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">for index in range(2600):</span><br><span class="line">    # 源文件路径</span><br><span class="line">    source_file = train_json[&#x27;filename&#x27;].iloc[index]</span><br><span class="line">    # 目标文件夹路径</span><br><span class="line">    target_directory = &#x27;data_use2/&#x27; + train_json[&#x27;weather&#x27;].iloc[index]</span><br><span class="line">    # 使用shutil的copy2函数复制文件</span><br><span class="line">    shutil.copy2(source_file, target_directory)</span><br></pre></td></tr></table></figure>



<p><strong>构建dataset 注意转换label</strong></p>
<p>label要从字符转换成数字</p>
<h4 id="识别通道不为3的"><a href="#识别通道不为3的" class="headerlink" title="识别通道不为3的"></a>识别通道不为3的</h4><p>将通道数不为3的找到然后删除了</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from PIL import Image</span><br><span class="line">import os</span><br><span class="line">import pandas as pd</span><br><span class="line">from PIL import Image</span><br><span class="line">import torchvision.transforms as T</span><br><span class="line">from torch.utils.data import Dataset</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import torch.optim as optim</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"># 数据路径</span><br><span class="line">train_root_dir = &quot;D:\python39\深度学习\weather\dataset_train1600&quot;</span><br><span class="line">test_root_dir = &quot;D:\python39\深度学习\weather\dataset_test1600&quot;</span><br><span class="line"></span><br><span class="line">cloudy_label_dir = &quot;cloudy&quot;</span><br><span class="line">foggy_label_dir = &quot;foggy&quot;</span><br><span class="line">rainy_label_dir = &quot;rainy&quot;</span><br><span class="line">shine_label_dir = &quot;shine&quot;</span><br><span class="line">snowy_label_dir = &quot;snowy&quot;</span><br><span class="line">sunrise_label_dir = &quot;sunrise&quot;</span><br><span class="line"></span><br><span class="line">def ist(root_dir, label_dir):</span><br><span class="line">    dir_path = os.path.join(root_dir, label_dir)</span><br><span class="line">    list_path = os.listdir(dir_path)</span><br><span class="line">    length = len(list_path)</span><br><span class="line">    for i in range(length):</span><br><span class="line">        img_name = list_path[i]</span><br><span class="line">        img_item_path = os.path.join(root_dir, label_dir, img_name)</span><br><span class="line">        img = Image.open(img_item_path)</span><br><span class="line">        dim = len(img.split())</span><br><span class="line">        if dim != 3:</span><br><span class="line">            print(&quot;&#123;&#125;的维度为&#123;&#125;&quot;.format(img_item_path, dim))</span><br><span class="line"></span><br><span class="line">ist(test_root_dir, cloudy_label_dir)</span><br></pre></td></tr></table></figure>

<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p><strong>基本卷积网络</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403221514828.png" alt="image-20240322151450732" loading="lazy"></p>
<p><strong>参考Google-Net引入inception模块后</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403221513811.png" alt="image-20240322151319595" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403221516401.png" alt="image-20240322151604263" loading="lazy"></p>
<p>明显提升训练速度</p>
<p><strong>再参考ResNet，加入Resblock</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403221516891.png" alt="image-20240322151639758" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403221516660.png" alt="image-20240322151649580" loading="lazy"></p>
<p>提升到85%</p>
<p><strong>基于预训练的ResNet34（迁移学习）</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202404271728441.png" alt="image-20240427172809329" loading="lazy"></p>
<p>总训练时间：2183.52 </p>
<p>平均测试时间：7.54 </p>
<p>FPS: 4002.74 </p>
<p>总时间：3580.64 </p>
<p>参数量: 21,287,750 </p>
<p>模型大小: 81.2063217163086 MB</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202404271727216.png" alt="image-20240427172711073" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202404271727985.png" alt="image-20240427172740890" loading="lazy"></p>
<p><strong>基于预训练的ResNet50（迁移学习）</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202404241654279.png" alt="image-20240424165441152" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202404241654490.png" alt="image-20240424165454419" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202404241655505.png" alt="image-20240424165503435" loading="lazy"></p>
<p><strong>基于预训练的GoogleNet（迁移学习）</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403301806618.png" alt="image-20240330180613474" loading="lazy"></p>
<p>——-第20轮训练——- </p>
<p>87.49604654312134 </p>
<p>accuracy on test set: 97 % [488/503]</p>
<p>该轮测试时间：-7.45   平均约7.63</p>
<p>总训练时间：2653.17</p>
<p> 参数量: 11,986,038</p>
<p><strong>注意力机制+迁移学习ResNet50</strong></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202403260117645.png" alt="image-20240326011705451" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202405021613845.png" alt="image-20240502161316752" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202405021613582.png" alt="image-20240502161350497" loading="lazy"></p>
<p><strong>vgg16</strong></p>
<p>训练一个epoch时间：1800.1</p>
<p>第二个：2175.05</p>
<p>该轮测试时间：8.90 </p>
<p>总训练时间：2681.96 </p>
<p>平均测试时间：9.46 </p>
<p>FPS: 3191.22 </p>
<p>程序总时间：2880.01 </p>
<p>参数量: 134,285,126 </p>
<p>模型大小: 512.2571029663086 MB</p>
<p>20个epoch</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202405021440393.png" alt="image-20240502144009242" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202405021441691.png" alt="image-20240502144132621" loading="lazy"></p>
<p>50个epoch</p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202404141716437.png" alt="image-20240414171647293" loading="lazy"></p>
<p><img src="https://raw.githubusercontent.com/Vayn3/image/main/img/202404141717291.png" alt="image-20240414171701223" loading="lazy"></p>
<h3 id="读取模型，随便取张图片来预测"><a href="#读取模型，随便取张图片来预测" class="headerlink" title="读取模型，随便取张图片来预测"></a>读取模型，随便取张图片来预测</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">model = resnet50()</span><br><span class="line">inchannel = model.fc.in_features</span><br><span class="line">model.fc = nn.Linear(inchannel, 6)</span><br><span class="line">model.load_state_dict(torch.load(&#x27;weather_Res50_10.pth&#x27;))</span><br><span class="line">model.eval()</span><br><span class="line"></span><br><span class="line">#数据处理</span><br><span class="line">weather_dict = &#123;</span><br><span class="line">    0: &quot;cloudy&quot;,</span><br><span class="line">    1: &quot;foggy&quot;,</span><br><span class="line">    2: &quot;rainy&quot;,</span><br><span class="line">    3: &quot;shine&quot;,</span><br><span class="line">    4: &quot;snowy&quot;,</span><br><span class="line">    5: &quot;sunrise&quot;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">img = Image.open(&#x27;testimage.jpg&#x27;)</span><br><span class="line"></span><br><span class="line">transform = T.Compose([</span><br><span class="line">            T.Resize(size=(256, 256)),  # 缩放</span><br><span class="line">            T.RandomCrop(size=(224, 224)),  # 随机裁减</span><br><span class="line">            T.ToTensor(),  # 将图片转换为Tensor,归一化至[0,1]</span><br><span class="line">            T.Normalize(mean=0.5, std=0.5)  # 标准化 减去均值除以标准差</span><br><span class="line">        ])</span><br><span class="line">image = transform(img)</span><br><span class="line">image = torch.reshape(image, (1, 3, 224, 224))</span><br><span class="line"></span><br><span class="line">#预测</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    output = model(image)</span><br><span class="line">print(output)</span><br><span class="line">index = output.argmax(1).item()</span><br><span class="line"></span><br><span class="line">#可视化</span><br><span class="line">print(weather_dict[index])</span><br><span class="line">img.show()</span><br></pre></td></tr></table></figure>



<h3 id="参数总结"><a href="#参数总结" class="headerlink" title="参数总结"></a>参数总结</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#返回参数</span><br><span class="line">def count_parameters(model):</span><br><span class="line">    return sum(p.numel() for p in model.parameters() if p.requires_grad)</span><br><span class="line"></span><br><span class="line">#计算模型大小</span><br><span class="line">def get_model_size(model):</span><br><span class="line">    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)#是否只算上计算梯度的参数 </span><br><span class="line">    total_size_in_bytes = total_params * torch.Tensor(1).storage().element_size()</span><br><span class="line">    total_size_in_mb = total_size_in_bytes / (1024 ** 2)</span><br><span class="line"></span><br><span class="line">    return total_size_in_mb</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th align="center">CNN 模型</th>
<th align="center">参数数量（M）</th>
<th align="center">模型大小(M)</th>
<th align="center">训练时间（min）</th>
<th align="center">识别时间(s)</th>
<th align="center">识别 FPS</th>
<th align="center">准确率(%)</th>
</tr>
</thead>
<tbody><tr>
<td align="center">VGG16</td>
<td align="center">134.29</td>
<td align="center">512.26</td>
<td align="center">44.70</td>
<td align="center">9.46</td>
<td align="center">53.19</td>
<td align="center">96.22</td>
</tr>
<tr>
<td align="center">GoogleNet</td>
<td align="center">11.98</td>
<td align="center">45.72</td>
<td align="center">44.22</td>
<td align="center">7.63</td>
<td align="center">65.92</td>
<td align="center">97.01</td>
</tr>
<tr>
<td align="center">ResNet34</td>
<td align="center">21.29</td>
<td align="center">81.21</td>
<td align="center">36.392</td>
<td align="center">7.54</td>
<td align="center">66.71</td>
<td align="center">96.82</td>
</tr>
<tr>
<td align="center">ResNet50</td>
<td align="center">23.52</td>
<td align="center">89.72</td>
<td align="center">56.18</td>
<td align="center">8.17</td>
<td align="center">61.58</td>
<td align="center">97.52</td>
</tr>
<tr>
<td align="center">CBAM_ResNet</td>
<td align="center">24.05</td>
<td align="center">91.73</td>
<td align="center">47.03</td>
<td align="center">8.13</td>
<td align="center">61.88</td>
<td align="center">98.41</td>
</tr>
</tbody></table>
</div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="打赏" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="reward-comment">I'm so cute. Please give me money.</div><div id="qr" style="display:none;"><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/alipay-qrcode.jpg"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/alipay-qrcode.jpg" alt="支付宝" title="支付宝"></a><div><span style="color:#00A3EE"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/qqpay-qrcode.png"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/qqpay-qrcode.png" alt="QQ 支付" title="QQ 支付"></a><div><span style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></span></div></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/wechatpay-qrcode.jpg"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/wechatpay-qrcode.jpg" alt="微信支付" title="微信支付"></a><div><span style="color:#2DC100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>Vayne</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="http://example.com/2021/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%9F%E5%A0%86/" title="pytorch入门笔记（土堆）">http://example.com/2021/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%9F%E5%A0%86/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2021/12/05/DeepLearning/" rel="prev" title="Deep Learning（吴恩达）"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">Deep Learning（吴恩达）</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2021/12/02/NumPy%E5%BA%93%E6%80%BB%E7%BB%93/" rel="next" title="NumPy库总结"><span class="post-nav-text">NumPy库总结</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div class="hty-card" id="comment"><div class="comment-tooltip text-center"><span>要不要和我说些什么？</span><br></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2025 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> Vayne</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v5.4.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.6.2</span></div></footer><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a></div></body></html>